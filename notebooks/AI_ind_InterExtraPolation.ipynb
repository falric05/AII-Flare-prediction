{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 22:45:37.320421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 22:45:37.463776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-21 22:45:37.463813: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-21 22:45:38.278955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 22:45:38.279119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 22:45:38.279132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, auc, roc_curve\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from Libs.config import inter_extra_data_folder\n",
    "from Libs.load_data import DataLoader, get_dataset_split\n",
    "from Libs.keras_f1score import f1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 1, 4, 1, 1, 1000), (30, 1, 4, 1, 1, 1000))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_std = False\n",
    "\n",
    "# initialize data loader\n",
    "data_loader = DataLoader(run=30, N=1000, s=0.5, t=[0.01, 0.1, 0.5, 3], d=0.2, m=1, \n",
    "                         override=False, folder=inter_extra_data_folder)\n",
    "# get the grid\n",
    "grid_X, grid_y = data_loader.get_grid()\n",
    "# get params dictionary\n",
    "params = data_loader.get_params()\n",
    "\n",
    "grid_X.shape, grid_y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biggest assumption when training ANNs is the following: \n",
    "\n",
    "\"We assume that training sets and test sets contains independent and identically distributed samples from the same unknown distribution $p_{data}(x,y)$\"\n",
    "\n",
    "This is a very important assumption that in general affect the performance ANNs, in particular classifier ones. We could, indeed, explore what can happen if we violete the following assumption. This a relevant application case, for exaple in cases when the generation parameters are not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(data1, mode, data2=None, F_std=False, overlap_size=15):\n",
    "    assert mode in ['all', 'interpolation', 'extrapolation']    \n",
    "\n",
    "    # params commons\n",
    "    dataset_split_params = {\n",
    "        'window_size': 20, # how large is the window\n",
    "        'overlap_size': overlap_size, # how many time interval of overlap there is between the windows\n",
    "        'label_treshold': 1, # how many labels have to be at 1 in the window_size to consider the current window as a flare\n",
    "        'split_on_run': True, # if True the windows of a run cannot be on different sets\n",
    "        'shuffle_run': False, # if True shuffles the order of the runs before computing the windows\n",
    "        'shuffle_window': False, # if True shuffles the order of the windows in the resulting dataframes\n",
    "        'test_size': 0.3, # size of the test set expressed in percentage\n",
    "        'val_size': 0.2, # size of the validation set expressed in percentage, considered only if get_validation is True\n",
    "        'get_validation': True, # if True the output would be train,val,test set, otherwise it would be train,test\n",
    "        'random_state': 42 # sets the seed for reproducibility\n",
    "    }\n",
    "\n",
    "    if mode in ['interpolation', 'extrapolation']:\n",
    "        assert not data2 is None\n",
    "        grid_X_train, grid_y_train = data1\n",
    "        grid_X_test, grid_y_test   = data2\n",
    "        # get the train and validation set, selecting the index for grid given the interpolation assuption\n",
    "        # notice that theta is the third parameter\n",
    "        df_train, df_val, _ = get_dataset_split(grid_X_train, grid_y_train, **dataset_split_params)\n",
    "        # get the test set, selecting the index for grid given the interpolation assuption\n",
    "        # notice that theta is the third parameter\n",
    "        _, _, df_test = get_dataset_split(grid_X_test, grid_y_test, **dataset_split_params)\n",
    "    elif mode in ['all']:\n",
    "        grid_X, grid_y = data1\n",
    "        # get all the dataset from a single list\n",
    "        df_train, df_val, df_test = get_dataset_split(grid_X, grid_y, **dataset_split_params)\n",
    "    \n",
    "    # number of classes\n",
    "    print('Training set:')\n",
    "    train_counts = df_train['future_flare'].value_counts()\n",
    "    print(train_counts, '\\n')\n",
    "    print('validation set:')\n",
    "    val_counts = df_val['future_flare'].value_counts()\n",
    "    print(val_counts, '\\n')\n",
    "    print('Test set:')\n",
    "    test_counts = df_test['future_flare'].value_counts()\n",
    "    print(test_counts, '\\n')\n",
    "    print('Total:')\n",
    "    total_counts = train_counts.add(val_counts).add(test_counts)\n",
    "    print(total_counts, '\\n')\n",
    "    print()\n",
    "    \n",
    "    # compute the initial bias to pass then to the model\n",
    "    initial_bias = Constant([np.log(train_counts[0]/train_counts[1])])\n",
    "\n",
    "    # check the shape\n",
    "    X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "    X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "    X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "    X = np.vstack((X_train, X_val, X_test))\n",
    "    y = np.hstack((y_train, y_val, y_test))\n",
    "    print('X ## Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n",
    "    print('y ## Train:', y_train.shape, 'Val:', y_val.shape, 'Test:', y_test.shape)\n",
    "\n",
    "    # finally, if requested, standardize the dataset\n",
    "    if F_std:\n",
    "        # Standardize Data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_std = scaler.transform(X_train)\n",
    "        X_val_std = scaler.transform(X_val)\n",
    "        X_test_std = scaler.transform(X_test)\n",
    "        # get automatically the number of classes\n",
    "        num_classes = len(np.unique(y))\n",
    "    else:\n",
    "        X_train_std = X_train\n",
    "        X_val_std = X_val\n",
    "        X_test_std = X_test\n",
    "\n",
    "\n",
    "    # finally return the dataset\n",
    "    return X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train, initial_bias):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid',bias_initializer=initial_bias))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=[f1_m, 'accuracy'])\n",
    "    # print the summury model\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, X_val, y_val, X_test, y_test):\n",
    "    # Validation set\n",
    "    y_pred = np.round(model.predict(X_val), 0)\n",
    "    print(\"### Evaluation on validation set ###\")\n",
    "    print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_val)))\n",
    "    print(\"F1 score: %.2f\" % (f1_score(y_pred, y_val, average='macro')))\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred, pos_label=1)\n",
    "    print('AUC:', auc(fpr, tpr))\n",
    "    #Create confusion matrix and normalizes it over predicted (columns)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # Test set\n",
    "    y_pred = np.round(model.predict(X_test), 0)\n",
    "    print(\"### Evaluation on test set ###\")\n",
    "    print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_test)))\n",
    "    print(\"F1 score: %.2f\" % (f1_score(y_pred, y_test, average='macro')))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    print('AUC:', auc(fpr, tpr))\n",
    "    #Create confusion matrix and normalizes it over predicted (columns)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model with multiple all theta parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct now the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    7197\n",
      "1    3779\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    3564\n",
      "1    1924\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    4547\n",
      "1    2509\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Total:\n",
      "0    15308\n",
      "1     8212\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "\n",
      "X ## Train: (10976, 20) Val: (5488, 20) Test: (7056, 20)\n",
      "y ## Train: (10976,) Val: (5488,) Test: (7056,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, initial_bias = get_data_set((grid_X, grid_y), 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 22:45:39.633675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-21 22:45:39.633733: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-21 22:45:39.633754: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (44910f15382a): /proc/driver/nvidia/version does not exist\n",
      "2023-03-21 22:45:39.634009: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 40)               3520      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model(X_train, initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "343/343 [==============================] - 6s 12ms/step - loss: 0.3836 - f1_m: 0.7206 - accuracy: 0.7792 - val_loss: 0.2857 - val_f1_m: 0.6372 - val_accuracy: 0.8613\n",
      "Epoch 2/20\n",
      "343/343 [==============================] - 3s 10ms/step - loss: 0.2702 - f1_m: 0.7984 - accuracy: 0.8727 - val_loss: 0.2525 - val_f1_m: 0.6425 - val_accuracy: 0.8885\n",
      "Epoch 3/20\n",
      "343/343 [==============================] - 3s 10ms/step - loss: 0.2554 - f1_m: 0.8202 - accuracy: 0.8852 - val_loss: 0.2434 - val_f1_m: 0.6553 - val_accuracy: 0.8954\n",
      "Epoch 4/20\n",
      "343/343 [==============================] - 3s 10ms/step - loss: 0.2416 - f1_m: 0.8346 - accuracy: 0.8960 - val_loss: 0.2261 - val_f1_m: 0.6578 - val_accuracy: 0.9011\n",
      "Epoch 5/20\n",
      "343/343 [==============================] - 4s 10ms/step - loss: 0.2336 - f1_m: 0.8393 - accuracy: 0.8981 - val_loss: 0.2186 - val_f1_m: 0.6633 - val_accuracy: 0.9056\n",
      "Epoch 6/20\n",
      "343/343 [==============================] - 3s 10ms/step - loss: 0.2286 - f1_m: 0.8453 - accuracy: 0.9019 - val_loss: 0.2241 - val_f1_m: 0.6527 - val_accuracy: 0.9018\n",
      "Epoch 7/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.2193 - f1_m: 0.8487 - accuracy: 0.9056 - val_loss: 0.2142 - val_f1_m: 0.6625 - val_accuracy: 0.9071\n",
      "Epoch 8/20\n",
      "343/343 [==============================] - 4s 10ms/step - loss: 0.2185 - f1_m: 0.8524 - accuracy: 0.9055 - val_loss: 0.2155 - val_f1_m: 0.6678 - val_accuracy: 0.9018\n",
      "Epoch 9/20\n",
      "343/343 [==============================] - 4s 10ms/step - loss: 0.2111 - f1_m: 0.8578 - accuracy: 0.9103 - val_loss: 0.2160 - val_f1_m: 0.6657 - val_accuracy: 0.9093\n",
      "Epoch 10/20\n",
      "343/343 [==============================] - 3s 10ms/step - loss: 0.2081 - f1_m: 0.8620 - accuracy: 0.9119 - val_loss: 0.2043 - val_f1_m: 0.6717 - val_accuracy: 0.9131\n",
      "Epoch 11/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.2028 - f1_m: 0.8631 - accuracy: 0.9145 - val_loss: 0.1956 - val_f1_m: 0.6772 - val_accuracy: 0.9165\n",
      "Epoch 12/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.2010 - f1_m: 0.8669 - accuracy: 0.9160 - val_loss: 0.1973 - val_f1_m: 0.6793 - val_accuracy: 0.9182\n",
      "Epoch 13/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1986 - f1_m: 0.8669 - accuracy: 0.9154 - val_loss: 0.1916 - val_f1_m: 0.6860 - val_accuracy: 0.9207\n",
      "Epoch 14/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1975 - f1_m: 0.8682 - accuracy: 0.9171 - val_loss: 0.2025 - val_f1_m: 0.6794 - val_accuracy: 0.9091\n",
      "Epoch 15/20\n",
      "343/343 [==============================] - 4s 10ms/step - loss: 0.1952 - f1_m: 0.8691 - accuracy: 0.9167 - val_loss: 0.2008 - val_f1_m: 0.6777 - val_accuracy: 0.9178\n",
      "Epoch 16/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1928 - f1_m: 0.8775 - accuracy: 0.9210 - val_loss: 0.1864 - val_f1_m: 0.6876 - val_accuracy: 0.9251\n",
      "Epoch 17/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1865 - f1_m: 0.8776 - accuracy: 0.9221 - val_loss: 0.1829 - val_f1_m: 0.6920 - val_accuracy: 0.9253\n",
      "Epoch 18/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1855 - f1_m: 0.8800 - accuracy: 0.9250 - val_loss: 0.1869 - val_f1_m: 0.6885 - val_accuracy: 0.9193\n",
      "Epoch 19/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1854 - f1_m: 0.8781 - accuracy: 0.9226 - val_loss: 0.1897 - val_f1_m: 0.6792 - val_accuracy: 0.9198\n",
      "Epoch 20/20\n",
      "343/343 [==============================] - 4s 11ms/step - loss: 0.1844 - f1_m: 0.8795 - accuracy: 0.9245 - val_loss: 0.1814 - val_f1_m: 0.6897 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f3c708eb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_allTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 1s 4ms/step\n",
      "### Evaluation on validation set ###\n",
      "Accuracy: 0.93\n",
      "F1 score: 0.92\n",
      "AUC: 0.9049772383105716\n",
      "[[3485   79]\n",
      " [ 323 1601]]\n",
      "\n",
      "221/221 [==============================] - 1s 4ms/step\n",
      "### Evaluation on test set ###\n",
      "Accuracy: 0.92\n",
      "F1 score: 0.91\n",
      "AUC: 0.8966187964804601\n",
      "[[4426  121]\n",
      " [ 452 2057]]\n"
     ]
    }
   ],
   "source": [
    "eval(model, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before, but now we are fitting only in the dataset coming from the generation with using just the extreme parameters: \n",
    "\n",
    "$\\theta=0.01$ and $\\theta=3$\n",
    "\n",
    "and a fraction of the other dataset, coming from $\\theta=0.1$ and $\\theta=0.5$ as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    3903\n",
      "1    1585\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    1975\n",
      "1     769\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    2042\n",
      "1    1486\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Total:\n",
      "0    7920\n",
      "1    3840\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "\n",
      "X ## Train: (5488, 20) Val: (2744, 20) Test: (3528, 20)\n",
      "y ## Train: (5488,) Val: (2744,) Test: (3528,)\n"
     ]
    }
   ],
   "source": [
    "p = 'theta'\n",
    "# train configurations\n",
    "theta_train_list     = [0.01, 3]\n",
    "theta_train_list_idx = [params[p].index(t) for t in theta_train_list]\n",
    "data_train = (grid_X[:,:,theta_train_list_idx,:,:,:], grid_y[:,:,theta_train_list_idx,:,:,:])\n",
    "# test configuration\n",
    "theta_test_list      = [0.1, 0.5]\n",
    "theta_test_list_idx  = [params[p].index(t) for t in theta_test_list]\n",
    "data_test = (grid_X[:,:,theta_test_list_idx,:,:,:], grid_y[:,:,theta_test_list_idx,:,:,:])\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, initial_bias = get_data_set(data_train, 'interpolation', data2=data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 40)               3520      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model(X_train, initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 5s 15ms/step - loss: 0.5598 - f1_m: 0.4603 - accuracy: 0.6279 - val_loss: 0.3139 - val_f1_m: 0.4448 - val_accuracy: 0.8509\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.3128 - f1_m: 0.6854 - accuracy: 0.8375 - val_loss: 0.2985 - val_f1_m: 0.4466 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.3125 - f1_m: 0.6910 - accuracy: 0.8373 - val_loss: 0.2990 - val_f1_m: 0.4553 - val_accuracy: 0.8560\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.3037 - f1_m: 0.6987 - accuracy: 0.8437 - val_loss: 0.3033 - val_f1_m: 0.3970 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.3004 - f1_m: 0.7170 - accuracy: 0.8499 - val_loss: 0.2949 - val_f1_m: 0.4095 - val_accuracy: 0.8477\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2951 - f1_m: 0.7114 - accuracy: 0.8478 - val_loss: 0.3120 - val_f1_m: 0.3756 - val_accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2936 - f1_m: 0.7201 - accuracy: 0.8499 - val_loss: 0.3170 - val_f1_m: 0.3565 - val_accuracy: 0.8349\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2957 - f1_m: 0.7041 - accuracy: 0.8482 - val_loss: 0.2767 - val_f1_m: 0.4428 - val_accuracy: 0.8626\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2881 - f1_m: 0.7185 - accuracy: 0.8535 - val_loss: 0.2726 - val_f1_m: 0.4482 - val_accuracy: 0.8644\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2832 - f1_m: 0.7229 - accuracy: 0.8590 - val_loss: 0.2661 - val_f1_m: 0.4760 - val_accuracy: 0.8732\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2826 - f1_m: 0.7125 - accuracy: 0.8551 - val_loss: 0.2770 - val_f1_m: 0.4369 - val_accuracy: 0.8659\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.2821 - f1_m: 0.7243 - accuracy: 0.8602 - val_loss: 0.2841 - val_f1_m: 0.4133 - val_accuracy: 0.8579\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.2759 - f1_m: 0.7330 - accuracy: 0.8624 - val_loss: 0.2617 - val_f1_m: 0.4596 - val_accuracy: 0.8728\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2692 - f1_m: 0.7414 - accuracy: 0.8642 - val_loss: 0.2622 - val_f1_m: 0.4560 - val_accuracy: 0.8757\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2808 - f1_m: 0.7242 - accuracy: 0.8577 - val_loss: 0.2566 - val_f1_m: 0.4675 - val_accuracy: 0.8765\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2672 - f1_m: 0.7439 - accuracy: 0.8701 - val_loss: 0.2555 - val_f1_m: 0.4684 - val_accuracy: 0.8776\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2695 - f1_m: 0.7443 - accuracy: 0.8673 - val_loss: 0.2681 - val_f1_m: 0.4930 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2742 - f1_m: 0.7381 - accuracy: 0.8633 - val_loss: 0.2582 - val_f1_m: 0.4910 - val_accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2621 - f1_m: 0.7569 - accuracy: 0.8750 - val_loss: 0.2539 - val_f1_m: 0.4569 - val_accuracy: 0.8794\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2691 - f1_m: 0.7478 - accuracy: 0.8710 - val_loss: 0.2511 - val_f1_m: 0.4921 - val_accuracy: 0.8841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f3c31d850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_intrpTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 4ms/step\n",
      "### Evaluation on validation set ###\n",
      "Accuracy: 0.88\n",
      "F1 score: 0.85\n",
      "AUC: 0.8452489670951918\n",
      "[[1844  131]\n",
      " [ 187  582]]\n",
      "\n",
      "111/111 [==============================] - 0s 4ms/step\n",
      "### Evaluation on test set ###\n",
      "Accuracy: 0.91\n",
      "F1 score: 0.90\n",
      "AUC: 0.8949786647297728\n",
      "[[1969   73]\n",
      " [ 259 1227]]\n"
     ]
    }
   ],
   "source": [
    "eval(model, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before, but now we are fitting only in the dataset coming from the generation without using the extreme parameters: \n",
    "\n",
    "$\\theta=0.1$ and $\\theta=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    3294\n",
      "1    2194\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    1589\n",
      "1    1155\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    2505\n",
      "1    1023\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Total:\n",
      "0    7388\n",
      "1    4372\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "\n",
      "X ## Train: (5488, 20) Val: (2744, 20) Test: (3528, 20)\n",
      "y ## Train: (5488,) Val: (2744,) Test: (3528,)\n"
     ]
    }
   ],
   "source": [
    "p = 'theta'\n",
    "# train configurations\n",
    "theta_train_list     = [0.1, 0.5]\n",
    "theta_train_list_idx = [params[p].index(t) for t in theta_train_list]\n",
    "data_train = (grid_X[:,:,theta_train_list_idx,:,:,:], grid_y[:,:,theta_train_list_idx,:,:,:])\n",
    "# test configuration\n",
    "theta_test_list      = [0.01, 3]\n",
    "theta_test_list_idx  = [params[p].index(t) for t in theta_test_list]\n",
    "data_test = (grid_X[:,:,theta_test_list_idx,:,:,:], grid_y[:,:,theta_test_list_idx,:,:,:])\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, initial_bias = get_data_set(data_train, 'extrapolation', data2=data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 40)               3520      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model(X_train, initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "172/172 [==============================] - 5s 14ms/step - loss: 0.4835 - f1_m: 0.7270 - accuracy: 0.7026 - val_loss: 0.2695 - val_f1_m: 0.8131 - val_accuracy: 0.8885\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2562 - f1_m: 0.8518 - accuracy: 0.8905 - val_loss: 0.2570 - val_f1_m: 0.8102 - val_accuracy: 0.8907\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2419 - f1_m: 0.8626 - accuracy: 0.8981 - val_loss: 0.2986 - val_f1_m: 0.7652 - val_accuracy: 0.8739\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2242 - f1_m: 0.8722 - accuracy: 0.9045 - val_loss: 0.2312 - val_f1_m: 0.8321 - val_accuracy: 0.8983\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2114 - f1_m: 0.8798 - accuracy: 0.9140 - val_loss: 0.2068 - val_f1_m: 0.8560 - val_accuracy: 0.9103\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2106 - f1_m: 0.8862 - accuracy: 0.9136 - val_loss: 0.2081 - val_f1_m: 0.8550 - val_accuracy: 0.9107\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2056 - f1_m: 0.8854 - accuracy: 0.9175 - val_loss: 0.2011 - val_f1_m: 0.8650 - val_accuracy: 0.9165\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.2027 - f1_m: 0.8877 - accuracy: 0.9158 - val_loss: 0.1988 - val_f1_m: 0.8600 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.1944 - f1_m: 0.8919 - accuracy: 0.9196 - val_loss: 0.1981 - val_f1_m: 0.8622 - val_accuracy: 0.9155\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.1917 - f1_m: 0.8967 - accuracy: 0.9222 - val_loss: 0.1994 - val_f1_m: 0.8721 - val_accuracy: 0.9187\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.1971 - f1_m: 0.8905 - accuracy: 0.9193 - val_loss: 0.1920 - val_f1_m: 0.8695 - val_accuracy: 0.9202\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.1908 - f1_m: 0.8978 - accuracy: 0.9242 - val_loss: 0.1876 - val_f1_m: 0.8683 - val_accuracy: 0.9206\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.1874 - f1_m: 0.8987 - accuracy: 0.9238 - val_loss: 0.1956 - val_f1_m: 0.8726 - val_accuracy: 0.9216\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 0.1855 - f1_m: 0.8970 - accuracy: 0.9237 - val_loss: 0.1861 - val_f1_m: 0.8664 - val_accuracy: 0.9213\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.1879 - f1_m: 0.8992 - accuracy: 0.9237 - val_loss: 0.1900 - val_f1_m: 0.8603 - val_accuracy: 0.9213\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.1781 - f1_m: 0.9102 - accuracy: 0.9319 - val_loss: 0.2265 - val_f1_m: 0.8630 - val_accuracy: 0.9074\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.1834 - f1_m: 0.9053 - accuracy: 0.9288 - val_loss: 0.1837 - val_f1_m: 0.8730 - val_accuracy: 0.9246\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 3s 18ms/step - loss: 0.1789 - f1_m: 0.8986 - accuracy: 0.9271 - val_loss: 0.1819 - val_f1_m: 0.8800 - val_accuracy: 0.9260\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.1800 - f1_m: 0.9040 - accuracy: 0.9288 - val_loss: 0.1855 - val_f1_m: 0.8687 - val_accuracy: 0.9231\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.1835 - f1_m: 0.8962 - accuracy: 0.9244 - val_loss: 0.1815 - val_f1_m: 0.8659 - val_accuracy: 0.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f24a1b550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_extrpTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 5ms/step\n",
      "### Evaluation on validation set ###\n",
      "Accuracy: 0.92\n",
      "F1 score: 0.92\n",
      "AUC: 0.912090699315369\n",
      "[[1538   51]\n",
      " [ 166  989]]\n",
      "\n",
      "111/111 [==============================] - 1s 5ms/step\n",
      "### Evaluation on test set ###\n",
      "Accuracy: 0.89\n",
      "F1 score: 0.86\n",
      "AUC: 0.8506365567984265\n",
      "[[2386  119]\n",
      " [ 257  766]]\n"
     ]
    }
   ],
   "source": [
    "eval(model, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further investigation in extrapolation with greater overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    16438\n",
      "1    11002\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    7930\n",
      "1    5790\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    12523\n",
      "1     5117\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Total:\n",
      "0    36891\n",
      "1    21909\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "\n",
      "X ## Train: (27440, 20) Val: (13720, 20) Test: (17640, 20)\n",
      "y ## Train: (27440,) Val: (13720,) Test: (17640,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, initial_bias = get_data_set(data_train, 'extrapolation', data2=data_test, overlap_size=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 40)               3520      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model(X_train, initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "858/858 [==============================] - 18s 18ms/step - loss: 0.2378 - f1_m: 0.8629 - accuracy: 0.8778 - val_loss: 0.1487 - val_f1_m: 0.6013 - val_accuracy: 0.9361\n",
      "Epoch 2/20\n",
      "858/858 [==============================] - 17s 19ms/step - loss: 0.1422 - f1_m: 0.9197 - accuracy: 0.9388 - val_loss: 0.1166 - val_f1_m: 0.6161 - val_accuracy: 0.9489\n",
      "Epoch 3/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.1168 - f1_m: 0.9349 - accuracy: 0.9502 - val_loss: 0.0984 - val_f1_m: 0.6207 - val_accuracy: 0.9614\n",
      "Epoch 4/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.1020 - f1_m: 0.9442 - accuracy: 0.9570 - val_loss: 0.1214 - val_f1_m: 0.6301 - val_accuracy: 0.9483\n",
      "Epoch 5/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0921 - f1_m: 0.9487 - accuracy: 0.9611 - val_loss: 0.0950 - val_f1_m: 0.6274 - val_accuracy: 0.9658\n",
      "Epoch 6/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0845 - f1_m: 0.9555 - accuracy: 0.9657 - val_loss: 0.0777 - val_f1_m: 0.6433 - val_accuracy: 0.9698\n",
      "Epoch 7/20\n",
      "858/858 [==============================] - 17s 20ms/step - loss: 0.0776 - f1_m: 0.9596 - accuracy: 0.9693 - val_loss: 0.0729 - val_f1_m: 0.6454 - val_accuracy: 0.9733\n",
      "Epoch 8/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0736 - f1_m: 0.9633 - accuracy: 0.9719 - val_loss: 0.0693 - val_f1_m: 0.6499 - val_accuracy: 0.9771\n",
      "Epoch 9/20\n",
      "858/858 [==============================] - 17s 19ms/step - loss: 0.0687 - f1_m: 0.9665 - accuracy: 0.9745 - val_loss: 0.0691 - val_f1_m: 0.6484 - val_accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0645 - f1_m: 0.9686 - accuracy: 0.9760 - val_loss: 0.0717 - val_f1_m: 0.6466 - val_accuracy: 0.9703\n",
      "Epoch 11/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0620 - f1_m: 0.9684 - accuracy: 0.9763 - val_loss: 0.0638 - val_f1_m: 0.6487 - val_accuracy: 0.9773\n",
      "Epoch 12/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0578 - f1_m: 0.9727 - accuracy: 0.9789 - val_loss: 0.0600 - val_f1_m: 0.6483 - val_accuracy: 0.9790\n",
      "Epoch 13/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0577 - f1_m: 0.9714 - accuracy: 0.9781 - val_loss: 0.0709 - val_f1_m: 0.6426 - val_accuracy: 0.9752\n",
      "Epoch 14/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0546 - f1_m: 0.9736 - accuracy: 0.9796 - val_loss: 0.0602 - val_f1_m: 0.6500 - val_accuracy: 0.9760\n",
      "Epoch 15/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0508 - f1_m: 0.9753 - accuracy: 0.9812 - val_loss: 0.0564 - val_f1_m: 0.6535 - val_accuracy: 0.9778\n",
      "Epoch 16/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0502 - f1_m: 0.9754 - accuracy: 0.9814 - val_loss: 0.0508 - val_f1_m: 0.6529 - val_accuracy: 0.9816\n",
      "Epoch 17/20\n",
      "858/858 [==============================] - 16s 19ms/step - loss: 0.0473 - f1_m: 0.9774 - accuracy: 0.9827 - val_loss: 0.0498 - val_f1_m: 0.6551 - val_accuracy: 0.9822\n",
      "Epoch 18/20\n",
      "858/858 [==============================] - 20s 23ms/step - loss: 0.0470 - f1_m: 0.9771 - accuracy: 0.9824 - val_loss: 0.0526 - val_f1_m: 0.6528 - val_accuracy: 0.9810\n",
      "Epoch 19/20\n",
      "858/858 [==============================] - 20s 23ms/step - loss: 0.0456 - f1_m: 0.9775 - accuracy: 0.9829 - val_loss: 0.0492 - val_f1_m: 0.6562 - val_accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "858/858 [==============================] - 34s 39ms/step - loss: 0.0453 - f1_m: 0.9781 - accuracy: 0.9833 - val_loss: 0.0486 - val_f1_m: 0.6562 - val_accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f3c2f16a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_extrpTheta19_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 2s 4ms/step\n",
      "### Evaluation on validation set ###\n",
      "Accuracy: 0.98\n",
      "F1 score: 0.98\n",
      "AUC: 0.9810361387529484\n",
      "[[7847   83]\n",
      " [ 159 5631]]\n",
      "\n",
      "552/552 [==============================] - 2s 4ms/step\n",
      "### Evaluation on test set ###\n",
      "Accuracy: 0.98\n",
      "F1 score: 0.97\n",
      "AUC: 0.9716514499777318\n",
      "[[12393   130]\n",
      " [  237  4880]]\n"
     ]
    }
   ],
   "source": [
    "eval(model, X_val, y_val, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
