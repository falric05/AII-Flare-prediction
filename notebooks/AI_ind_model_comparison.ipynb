{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef34084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 16:39:29.264936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 16:39:29.476431: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:39:29.476476: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 16:39:30.370168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:39:30.370328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:39:30.370342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from Libs.load_data import DataLoader, get_dataset_split\n",
    "from Libs.config import models_data_folder\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, auc, roc_curve\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057f5da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run': 100,\n",
       " 'sigma': [0.5],\n",
       " 'theta': [0.01],\n",
       " 'mu': [1],\n",
       " 'delta': [0.2],\n",
       " 'N': 1000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(run=100, N=1000, s=0.5, t=0.01, d=0.2, m=1, override=False, folder=models_data_folder)\n",
    "params = data_loader.get_params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7361ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, best_labels = data_loader.get_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd04989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split_params = {\n",
    "    'window_size': 20, # how large is the window\n",
    "    'overlap_size': None, # how many time interval of overlap there is between the windows\n",
    "    'label_treshold': 1, # how many labels have to be at 1 in the window_size to consider the current window as a flare\n",
    "    'split_on_run': True, # if True the windows of a run cannot be on different sets\n",
    "    'shuffle_run': False, # if True shuffles the order of the runs before computing the windows\n",
    "    'shuffle_window': False, # if True shuffles the order of the windows in the resulting dataframes\n",
    "    'test_size': 0.3, # size of the test set expressed in percentage\n",
    "    'val_size': 0.2, # size of the validation set expressed in percentage, considered only if get_validation is True\n",
    "    'get_validation': True, # if True the output would be train,val,test set, otherwise it would be train,test\n",
    "    'random_state': 42 # sets the seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbbe285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    if num_classes==2:\n",
    "        output_layer = keras.layers.Dense(1, activation=\"sigmoid\", bias_initializer=output_bias)(gap)\n",
    "    else:\n",
    "        output_layer = keras.layers.Dense(num_classes, activation=\"softmax\", bias_initializer=output_bias)(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "def make_lstm(input_shape, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=input_shape))\n",
    "    lstm_model.add(Dense(30, activation='relu'))\n",
    "    lstm_model.add(Dense(10, activation='relu'))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid',bias_initializer=output_bias))\n",
    "    return lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a72d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 16:39:44.648942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-20 16:39:44.649008: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-20 16:39:44.649049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5166cf34c918): /proc/driver/nvidia/version does not exist\n",
      "2023-03-20 16:39:44.649288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 3ms/step\n",
      "46/46 [==============================] - 1s 5ms/step\n",
      "61/61 [==============================] - 0s 3ms/step\n",
      "61/61 [==============================] - 1s 6ms/step\n",
      "92/92 [==============================] - 1s 4ms/step\n",
      "92/92 [==============================] - 1s 4ms/step\n",
      "184/184 [==============================] - 1s 4ms/step\n",
      "184/184 [==============================] - 1s 4ms/step\n",
      "919/919 [==============================] - 3s 3ms/step\n",
      "919/919 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'cnn': {'f1_macro': 0.8619983946752034, 'auc': 0.8997071969540206},\n",
       "  'dt': {'f1_macro': 0.8865640709057236, 'auc': 0.863065430617059},\n",
       "  'knn': {'f1_macro': 0.8673563245156484, 'auc': 0.8272824152630055},\n",
       "  'lp': {'f1_macro': 0.8117277501027982, 'auc': 0.7427730414269751},\n",
       "  'nb': {'f1_macro': 0.8597675373531555, 'auc': 0.8368269668501428},\n",
       "  'svc': {'f1_macro': 0.8600487634970393, 'auc': 0.9019989239746721},\n",
       "  'lstm': {'f1_macro': 0.8791733836755473, 'auc': 0.8699406116790134}},\n",
       " 5: {'cnn': {'f1_macro': 0.9039006833974363, 'auc': 0.8975346107181018},\n",
       "  'dt': {'f1_macro': 0.913342576791809, 'auc': 0.9040368794901271},\n",
       "  'knn': {'f1_macro': 0.9173728813559321, 'auc': 0.8854726198163554},\n",
       "  'lp': {'f1_macro': 0.8776512238882481, 'auc': 0.9101091385036819},\n",
       "  'nb': {'f1_macro': 0.8807420871628138, 'auc': 0.887609638009967},\n",
       "  'svc': {'f1_macro': 0.8800020742943078, 'auc': 0.8980181907158433},\n",
       "  'lstm': {'f1_macro': 0.901032047080942, 'auc': 0.8947113143241029}},\n",
       " 10: {'cnn': {'f1_macro': 0.9393173455145286, 'auc': 0.9054912746585736},\n",
       "  'dt': {'f1_macro': 0.9341089589533829, 'auc': 0.9170693235364586},\n",
       "  'knn': {'f1_macro': 0.9424193627092179, 'auc': 0.9160560258765273},\n",
       "  'lp': {'f1_macro': 0.9107227776663708, 'auc': 0.94788255730373},\n",
       "  'nb': {'f1_macro': 0.9192856001916779, 'auc': 0.9192856001916779},\n",
       "  'svc': {'f1_macro': 0.9254233208743912, 'auc': 0.9502211285041131},\n",
       "  'lstm': {'f1_macro': 0.9427910940911373, 'auc': 0.9260517330884114}},\n",
       " 15: {'cnn': {'f1_macro': 0.9583642580481646, 'auc': 0.93501262363051},\n",
       "  'dt': {'f1_macro': 0.9657639874159522, 'auc': 0.9570703912167328},\n",
       "  'knn': {'f1_macro': 0.966190661160404, 'auc': 0.9507979524239687},\n",
       "  'lp': {'f1_macro': 0.9444457298029734, 'auc': 0.9613716906399833},\n",
       "  'nb': {'f1_macro': 0.946033666381594, 'auc': 0.9540430361568573},\n",
       "  'svc': {'f1_macro': 0.9525788172213504, 'auc': 0.9724156301392074},\n",
       "  'lstm': {'f1_macro': 0.962453768259494, 'auc': 0.9641141454149583}},\n",
       " 19: {'cnn': {'f1_macro': 0.9352496160524308, 'auc': 0.8949675324675325},\n",
       "  'dt': {'f1_macro': 0.986643177309287, 'auc': 0.9855968499585521},\n",
       "  'knn': {'f1_macro': 0.9804445554584906, 'auc': 0.9700469743022934},\n",
       "  'lp': {'f1_macro': 0.9526926482837855, 'auc': 0.9765266648245371},\n",
       "  'nb': {'f1_macro': 0.9623441619823007, 'auc': 0.9765318458137607},\n",
       "  'svc': {'f1_macro': 0.975203045923033, 'auc': 0.9900559546836143},\n",
       "  'lstm': {'f1_macro': 0.9913381216154487, 'auc': 0.9937327300359216}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lbls = ['dt', 'nb', 'lp', 'svc', 'knn', 'cnn', 'lstm']\n",
    "\n",
    "results = {}\n",
    "\n",
    "models_folder = \"models\"\n",
    "for overlap_size in np.sort([int(name.split('_')[1]) for name in os.listdir(models_folder)]):\n",
    "    dataset_split_params['overlap_size'] = overlap_size\n",
    "    df_train, df_val, df_test = get_dataset_split(Xs, best_labels, **dataset_split_params)\n",
    "\n",
    "    X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "    X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "    X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_std = scaler.transform(X_train)\n",
    "    X_val_std = scaler.transform(X_val)\n",
    "    X_test_std = scaler.transform(X_test)\n",
    "    # Make the data uniform to multivariate timeseries\n",
    "    X_train_cnn = X_train_std.reshape((X_train_std.shape[0], X_train_std.shape[1], 1))\n",
    "    X_val_cnn = X_val_std.reshape((X_val_std.shape[0], X_val_std.shape[1], 1))\n",
    "    X_test_cnn = X_test_std.reshape((X_test_std.shape[0], X_test_std.shape[1], 1))\n",
    "    \n",
    "    results[overlap_size] = {}\n",
    "    \n",
    "    overlap_folder = os.path.join(models_folder, f'overlap_{overlap_size}')\n",
    "    for m in os.listdir(overlap_folder):\n",
    "        filename, extension = m.split('.')\n",
    "        if extension != 'pickle':\n",
    "            if extension == 'pkl':\n",
    "                model_type = filename.split('_')[-1]\n",
    "                clf = joblib.load(os.path.join(overlap_folder, m))\n",
    "                y_pred = clf.predict(X_test)\n",
    "            if extension == 'h5':\n",
    "                model_type = filename.split('_')[0].lower()\n",
    "                if  model_type == 'cnn':\n",
    "                    model = make_model(input_shape=X_train_cnn.shape[1:], num_classes=2)\n",
    "                if model_type == 'lstm':\n",
    "                    model = make_lstm((X_train_std.shape[1], 1))\n",
    "                model.load_weights(os.path.join(overlap_folder, m))\n",
    "                if model_type == 'cnn':\n",
    "                    y_pred = np.round(model.predict(X_test_cnn), 0)\n",
    "                if model_type == 'lstm':\n",
    "                    y_pred = np.round(model.predict(X_test_std), 0)\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "            results[overlap_size][model_type] = {}\n",
    "            results[overlap_size][model_type]['f1_macro'] = f1_score(y_test, y_pred, average='macro')\n",
    "            results[overlap_size][model_type]['auc'] = auc(fpr, tpr)\n",
    "                \n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39656aa",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "\\[1\\] _On the distribution of fluxes of gamma-ray blazars: hints for a stochastic process?_, Tavecchio et al., [https://arxiv.org/pdf/2004.09149.pdf](https://arxiv.org/pdf/2004.09149.pdf)\n",
    "<!-- cite with: [\\[1\\]](https://arxiv.org/pdf/2004.09149.pdf)  -->\n",
    "\\[2\\] _Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline_, Wang et al., [https://arxiv.org/abs/1611.06455](https://arxiv.org/abs/1611.06455)\n",
    "<!-- cite with: [\\[2\\]](https://arxiv.org/abs/1611.06455)  -->\n",
    "\\[3\\] _Solar Flare Prediction Based on the Fusion of Multiple Deep-learning Models_, Tang et al., [https://iopscience.iop.org/article/10.3847/1538-4365/ac249e/meta](https://iopscience.iop.org/article/10.3847/1538-4365/ac249e/meta)\n",
    "<!-- cite with: [\\[3\\]](https://iopscience.iop.org/article/10.3847/1538-4365/ac249e/meta)  -->\n",
    "\\[4\\] _Predicting Solar Energetic Particles Using SDO/HMI Vector Magnetic Data Products and a Bidirectional LSTM Network_, Abduallah et al., [https://iopscience.iop.org/article/10.3847/1538-4365/ac5f56/meta](https://iopscience.iop.org/article/10.3847/1538-4365/ac5f56/meta)\n",
    "<!-- cite with: [\\[4\\]](https://iopscience.iop.org/article/10.3847/1538-4365/ac5f56/meta) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
