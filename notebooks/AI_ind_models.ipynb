{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZUhJEvf-tKM"
   },
   "source": [
    "# AI in Industry project\n",
    "# Flare prediction\n",
    "- Ildebrando Simeoni - ildebrando.simeoni@studio.unibo.it\n",
    "- Davide Femia - davide.femia@studio.unibo.it\n",
    "- Riccardo Falco - riccardo.falco2@tudio.unibo.it\n",
    "- Vincenzo Collura - vincenzo.collura2@studio.unibo.it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_Rs7TGB9lqq"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IMy1hxhX-tKP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Libs.load_data import DataLoader, ClassificationDataLoader, get_dataset_split\n",
    "import Libs.flares_plot as fplt\n",
    "from Libs.threshold import get_labels_physic, get_labels_KDE, get_labels_quantile, get_labels_quantile_on_run\n",
    "from Libs.keras_f1score import f1_m\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, auc, roc_curve\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-P2pI3e92tC"
   },
   "source": [
    "## Dataframe building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AMoQ55Y194rM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run': 100,\n",
       " 'sigma': [0.5],\n",
       " 'theta': [0.01],\n",
       " 'mu': [1],\n",
       " 'delta': [0.2],\n",
       " 'N': 1000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: sostituire tutte le seguenti celle con la funzione di Davide per creare il dataframe con cui traineremo tutti i modelli\n",
    "data_loader = ClassificationDataLoader(run=100, N=1000, s=0.5, t=0.01, d=0.2, m=1, override=True)\n",
    "params = data_loader.get_params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 191.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels\n",
      "Labels Loaded\n"
     ]
    }
   ],
   "source": [
    "Xs, best_labels = data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>t_9</th>\n",
       "      <th>...</th>\n",
       "      <th>t_11</th>\n",
       "      <th>t_12</th>\n",
       "      <th>t_13</th>\n",
       "      <th>t_14</th>\n",
       "      <th>t_15</th>\n",
       "      <th>t_16</th>\n",
       "      <th>t_17</th>\n",
       "      <th>t_18</th>\n",
       "      <th>t_19</th>\n",
       "      <th>future_flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>1.398585</td>\n",
       "      <td>1.438386</td>\n",
       "      <td>1.689048</td>\n",
       "      <td>1.966308</td>\n",
       "      <td>2.568122</td>\n",
       "      <td>2.375319</td>\n",
       "      <td>4.190594</td>\n",
       "      <td>...</td>\n",
       "      <td>2.845157</td>\n",
       "      <td>4.779448</td>\n",
       "      <td>6.001102</td>\n",
       "      <td>7.958019</td>\n",
       "      <td>6.858917</td>\n",
       "      <td>6.741916</td>\n",
       "      <td>5.873234</td>\n",
       "      <td>5.157005</td>\n",
       "      <td>6.109012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.998950</td>\n",
       "      <td>1.398585</td>\n",
       "      <td>1.438386</td>\n",
       "      <td>1.689048</td>\n",
       "      <td>1.966308</td>\n",
       "      <td>2.568122</td>\n",
       "      <td>2.375319</td>\n",
       "      <td>4.190594</td>\n",
       "      <td>3.259339</td>\n",
       "      <td>...</td>\n",
       "      <td>4.779448</td>\n",
       "      <td>6.001102</td>\n",
       "      <td>7.958019</td>\n",
       "      <td>6.858917</td>\n",
       "      <td>6.741916</td>\n",
       "      <td>5.873234</td>\n",
       "      <td>5.157005</td>\n",
       "      <td>6.109012</td>\n",
       "      <td>6.309733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998950</td>\n",
       "      <td>1.398585</td>\n",
       "      <td>1.438386</td>\n",
       "      <td>1.689048</td>\n",
       "      <td>1.966308</td>\n",
       "      <td>2.568122</td>\n",
       "      <td>2.375319</td>\n",
       "      <td>4.190594</td>\n",
       "      <td>3.259339</td>\n",
       "      <td>2.845157</td>\n",
       "      <td>...</td>\n",
       "      <td>6.001102</td>\n",
       "      <td>7.958019</td>\n",
       "      <td>6.858917</td>\n",
       "      <td>6.741916</td>\n",
       "      <td>5.873234</td>\n",
       "      <td>5.157005</td>\n",
       "      <td>6.109012</td>\n",
       "      <td>6.309733</td>\n",
       "      <td>6.209758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.398585</td>\n",
       "      <td>1.438386</td>\n",
       "      <td>1.689048</td>\n",
       "      <td>1.966308</td>\n",
       "      <td>2.568122</td>\n",
       "      <td>2.375319</td>\n",
       "      <td>4.190594</td>\n",
       "      <td>3.259339</td>\n",
       "      <td>2.845157</td>\n",
       "      <td>4.779448</td>\n",
       "      <td>...</td>\n",
       "      <td>7.958019</td>\n",
       "      <td>6.858917</td>\n",
       "      <td>6.741916</td>\n",
       "      <td>5.873234</td>\n",
       "      <td>5.157005</td>\n",
       "      <td>6.109012</td>\n",
       "      <td>6.309733</td>\n",
       "      <td>6.209758</td>\n",
       "      <td>7.490564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.438386</td>\n",
       "      <td>1.689048</td>\n",
       "      <td>1.966308</td>\n",
       "      <td>2.568122</td>\n",
       "      <td>2.375319</td>\n",
       "      <td>4.190594</td>\n",
       "      <td>3.259339</td>\n",
       "      <td>2.845157</td>\n",
       "      <td>4.779448</td>\n",
       "      <td>6.001102</td>\n",
       "      <td>...</td>\n",
       "      <td>6.858917</td>\n",
       "      <td>6.741916</td>\n",
       "      <td>5.873234</td>\n",
       "      <td>5.157005</td>\n",
       "      <td>6.109012</td>\n",
       "      <td>6.309733</td>\n",
       "      <td>6.209758</td>\n",
       "      <td>7.490564</td>\n",
       "      <td>12.011101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48015</th>\n",
       "      <td>0.149848</td>\n",
       "      <td>0.129055</td>\n",
       "      <td>0.139069</td>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.150383</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.147091</td>\n",
       "      <td>0.157011</td>\n",
       "      <td>0.183645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>0.249556</td>\n",
       "      <td>0.214295</td>\n",
       "      <td>0.186991</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.164884</td>\n",
       "      <td>0.140189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48016</th>\n",
       "      <td>0.129055</td>\n",
       "      <td>0.139069</td>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.150383</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.147091</td>\n",
       "      <td>0.157011</td>\n",
       "      <td>0.183645</td>\n",
       "      <td>0.198442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249556</td>\n",
       "      <td>0.214295</td>\n",
       "      <td>0.186991</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.164884</td>\n",
       "      <td>0.140189</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48017</th>\n",
       "      <td>0.139069</td>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.150383</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.147091</td>\n",
       "      <td>0.157011</td>\n",
       "      <td>0.183645</td>\n",
       "      <td>0.198442</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214295</td>\n",
       "      <td>0.186991</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.164884</td>\n",
       "      <td>0.140189</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0.265009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48018</th>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.150383</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.147091</td>\n",
       "      <td>0.157011</td>\n",
       "      <td>0.183645</td>\n",
       "      <td>0.198442</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>0.249556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186991</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.164884</td>\n",
       "      <td>0.140189</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0.265009</td>\n",
       "      <td>0.206403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48019</th>\n",
       "      <td>0.150383</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.147091</td>\n",
       "      <td>0.157011</td>\n",
       "      <td>0.183645</td>\n",
       "      <td>0.198442</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>0.249556</td>\n",
       "      <td>0.214295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>0.164884</td>\n",
       "      <td>0.140189</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0.265009</td>\n",
       "      <td>0.206403</td>\n",
       "      <td>0.143045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48020 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_0       t_1       t_2       t_3       t_4       t_5       t_6  \\\n",
       "0      1.000000  0.975000  0.998950  1.398585  1.438386  1.689048  1.966308   \n",
       "1      0.975000  0.998950  1.398585  1.438386  1.689048  1.966308  2.568122   \n",
       "2      0.998950  1.398585  1.438386  1.689048  1.966308  2.568122  2.375319   \n",
       "3      1.398585  1.438386  1.689048  1.966308  2.568122  2.375319  4.190594   \n",
       "4      1.438386  1.689048  1.966308  2.568122  2.375319  4.190594  3.259339   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "48015  0.149848  0.129055  0.139069  0.121771  0.150383  0.152603  0.149203   \n",
       "48016  0.129055  0.139069  0.121771  0.150383  0.152603  0.149203  0.147091   \n",
       "48017  0.139069  0.121771  0.150383  0.152603  0.149203  0.147091  0.157011   \n",
       "48018  0.121771  0.150383  0.152603  0.149203  0.147091  0.157011  0.183645   \n",
       "48019  0.150383  0.152603  0.149203  0.147091  0.157011  0.183645  0.198442   \n",
       "\n",
       "            t_7       t_8       t_9  ...      t_11      t_12      t_13  \\\n",
       "0      2.568122  2.375319  4.190594  ...  2.845157  4.779448  6.001102   \n",
       "1      2.375319  4.190594  3.259339  ...  4.779448  6.001102  7.958019   \n",
       "2      4.190594  3.259339  2.845157  ...  6.001102  7.958019  6.858917   \n",
       "3      3.259339  2.845157  4.779448  ...  7.958019  6.858917  6.741916   \n",
       "4      2.845157  4.779448  6.001102  ...  6.858917  6.741916  5.873234   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "48015  0.147091  0.157011  0.183645  ...  0.186560  0.249556  0.214295   \n",
       "48016  0.157011  0.183645  0.198442  ...  0.249556  0.214295  0.186991   \n",
       "48017  0.183645  0.198442  0.186560  ...  0.214295  0.186991  0.225031   \n",
       "48018  0.198442  0.186560  0.249556  ...  0.186991  0.225031  0.184697   \n",
       "48019  0.186560  0.249556  0.214295  ...  0.225031  0.184697  0.171653   \n",
       "\n",
       "           t_14      t_15      t_16      t_17      t_18       t_19  \\\n",
       "0      7.958019  6.858917  6.741916  5.873234  5.157005   6.109012   \n",
       "1      6.858917  6.741916  5.873234  5.157005  6.109012   6.309733   \n",
       "2      6.741916  5.873234  5.157005  6.109012  6.309733   6.209758   \n",
       "3      5.873234  5.157005  6.109012  6.309733  6.209758   7.490564   \n",
       "4      5.157005  6.109012  6.309733  6.209758  7.490564  12.011101   \n",
       "...         ...       ...       ...       ...       ...        ...   \n",
       "48015  0.186991  0.225031  0.184697  0.171653  0.164884   0.140189   \n",
       "48016  0.225031  0.184697  0.171653  0.164884  0.140189   0.213669   \n",
       "48017  0.184697  0.171653  0.164884  0.140189  0.213669   0.265009   \n",
       "48018  0.171653  0.164884  0.140189  0.213669  0.265009   0.206403   \n",
       "48019  0.164884  0.140189  0.213669  0.265009  0.206403   0.143045   \n",
       "\n",
       "       future_flare  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "48015             0  \n",
       "48016             0  \n",
       "48017             0  \n",
       "48018             0  \n",
       "48019             0  \n",
       "\n",
       "[48020 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindexes = data_loader.get_standard_indexes()\n",
    "\n",
    "dataset_split_params = {\n",
    "    'window_size': 20, # how large is the window\n",
    "    'overlap_size': 19, # how many time interval of overlap there is between the windows\n",
    "    'label_treshold': 1, # how many labels have to be at 1 in the window_size to consider the current window as a flare\n",
    "    'split_on_run': True, # if True the windows of a run cannot be on different sets\n",
    "    'shuffle_run': False, # if True shuffles the order of the runs before computing the windows\n",
    "    'shuffle_window': False, # if True shuffles the order of the windows in the resulting dataframes\n",
    "    'test_size': 0.3, # size of the test set expressed in percentage\n",
    "    'val_size': 0.2, # size of the validation set expressed in percentage, considered only if get_validation is True\n",
    "    'get_validation': True, # if True the output would be train,val,test set, otherwise it would be train,test\n",
    "    'random_state': 42 # sets the seed for reproducibility\n",
    "}\n",
    "df_train, df_val, df_test = get_dataset_split(Xs, best_labels, bindexes, **dataset_split_params)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>t_9</th>\n",
       "      <th>...</th>\n",
       "      <th>t_11</th>\n",
       "      <th>t_12</th>\n",
       "      <th>t_13</th>\n",
       "      <th>t_14</th>\n",
       "      <th>t_15</th>\n",
       "      <th>t_16</th>\n",
       "      <th>t_17</th>\n",
       "      <th>t_18</th>\n",
       "      <th>t_19</th>\n",
       "      <th>future_flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305069</td>\n",
       "      <td>0.357454</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.538898</td>\n",
       "      <td>0.638365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357454</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.538898</td>\n",
       "      <td>0.638365</td>\n",
       "      <td>0.442731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.305069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.538898</td>\n",
       "      <td>0.638365</td>\n",
       "      <td>0.442731</td>\n",
       "      <td>0.372533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.812385</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.305069</td>\n",
       "      <td>0.357454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259115</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.538898</td>\n",
       "      <td>0.638365</td>\n",
       "      <td>0.442731</td>\n",
       "      <td>0.372533</td>\n",
       "      <td>0.324243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.624754</td>\n",
       "      <td>0.440110</td>\n",
       "      <td>0.433272</td>\n",
       "      <td>0.380983</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.305069</td>\n",
       "      <td>0.357454</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.538898</td>\n",
       "      <td>0.638365</td>\n",
       "      <td>0.442731</td>\n",
       "      <td>0.372533</td>\n",
       "      <td>0.324243</td>\n",
       "      <td>0.289455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>0.283386</td>\n",
       "      <td>0.338322</td>\n",
       "      <td>0.529959</td>\n",
       "      <td>0.498035</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.439616</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474821</td>\n",
       "      <td>0.781296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662463</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>0.582110</td>\n",
       "      <td>0.470944</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>0.338322</td>\n",
       "      <td>0.529959</td>\n",
       "      <td>0.498035</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.439616</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474821</td>\n",
       "      <td>0.781296</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>0.582110</td>\n",
       "      <td>0.470944</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20577</th>\n",
       "      <td>0.529959</td>\n",
       "      <td>0.498035</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.439616</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474821</td>\n",
       "      <td>0.781296</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.662463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582110</td>\n",
       "      <td>0.470944</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>0.314113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20578</th>\n",
       "      <td>0.498035</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.439616</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474821</td>\n",
       "      <td>0.781296</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.662463</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470944</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>0.314113</td>\n",
       "      <td>0.315094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.439616</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>0.493962</td>\n",
       "      <td>0.474821</td>\n",
       "      <td>0.781296</td>\n",
       "      <td>0.648389</td>\n",
       "      <td>0.662463</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>0.582110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547727</td>\n",
       "      <td>0.589551</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.381218</td>\n",
       "      <td>0.314113</td>\n",
       "      <td>0.315094</td>\n",
       "      <td>0.353672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20580 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_0       t_1       t_2       t_3       t_4       t_5       t_6  \\\n",
       "0      1.000000  0.975000  0.684336  0.812385  0.750157  0.624754  0.440110   \n",
       "1      0.975000  0.684336  0.812385  0.750157  0.624754  0.440110  0.433272   \n",
       "2      0.684336  0.812385  0.750157  0.624754  0.440110  0.433272  0.380983   \n",
       "3      0.812385  0.750157  0.624754  0.440110  0.433272  0.380983  0.313313   \n",
       "4      0.750157  0.624754  0.440110  0.433272  0.380983  0.313313  0.193705   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20575  0.283386  0.338322  0.529959  0.498035  0.432169  0.439616  0.506125   \n",
       "20576  0.338322  0.529959  0.498035  0.432169  0.439616  0.506125  0.493962   \n",
       "20577  0.529959  0.498035  0.432169  0.439616  0.506125  0.493962  0.474821   \n",
       "20578  0.498035  0.432169  0.439616  0.506125  0.493962  0.474821  0.781296   \n",
       "20579  0.432169  0.439616  0.506125  0.493962  0.474821  0.781296  0.648389   \n",
       "\n",
       "            t_7       t_8       t_9  ...      t_11      t_12      t_13  \\\n",
       "0      0.433272  0.380983  0.313313  ...  0.305069  0.357454  0.300547   \n",
       "1      0.380983  0.313313  0.193705  ...  0.357454  0.300547  0.259115   \n",
       "2      0.313313  0.193705  0.305069  ...  0.300547  0.259115  0.346266   \n",
       "3      0.193705  0.305069  0.357454  ...  0.259115  0.346266  0.361283   \n",
       "4      0.305069  0.357454  0.300547  ...  0.346266  0.361283  0.574706   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "20575  0.493962  0.474821  0.781296  ...  0.662463  0.467084  0.582110   \n",
       "20576  0.474821  0.781296  0.648389  ...  0.467084  0.582110  0.470944   \n",
       "20577  0.781296  0.648389  0.662463  ...  0.582110  0.470944  0.547727   \n",
       "20578  0.648389  0.662463  0.467084  ...  0.470944  0.547727  0.589551   \n",
       "20579  0.662463  0.467084  0.582110  ...  0.547727  0.589551  0.598332   \n",
       "\n",
       "           t_14      t_15      t_16      t_17      t_18      t_19  \\\n",
       "0      0.259115  0.346266  0.361283  0.574706  0.538898  0.638365   \n",
       "1      0.346266  0.361283  0.574706  0.538898  0.638365  0.442731   \n",
       "2      0.361283  0.574706  0.538898  0.638365  0.442731  0.372533   \n",
       "3      0.574706  0.538898  0.638365  0.442731  0.372533  0.324243   \n",
       "4      0.538898  0.638365  0.442731  0.372533  0.324243  0.289455   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "20575  0.470944  0.547727  0.589551  0.598332  0.422484  0.477675   \n",
       "20576  0.547727  0.589551  0.598332  0.422484  0.477675  0.381218   \n",
       "20577  0.589551  0.598332  0.422484  0.477675  0.381218  0.314113   \n",
       "20578  0.598332  0.422484  0.477675  0.381218  0.314113  0.315094   \n",
       "20579  0.422484  0.477675  0.381218  0.314113  0.315094  0.353672   \n",
       "\n",
       "       future_flare  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "20575             0  \n",
       "20576             0  \n",
       "20577             0  \n",
       "20578             0  \n",
       "20579             0  \n",
       "\n",
       "[20580 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_1</th>\n",
       "      <th>t_2</th>\n",
       "      <th>t_3</th>\n",
       "      <th>t_4</th>\n",
       "      <th>t_5</th>\n",
       "      <th>t_6</th>\n",
       "      <th>t_7</th>\n",
       "      <th>t_8</th>\n",
       "      <th>t_9</th>\n",
       "      <th>...</th>\n",
       "      <th>t_11</th>\n",
       "      <th>t_12</th>\n",
       "      <th>t_13</th>\n",
       "      <th>t_14</th>\n",
       "      <th>t_15</th>\n",
       "      <th>t_16</th>\n",
       "      <th>t_17</th>\n",
       "      <th>t_18</th>\n",
       "      <th>t_19</th>\n",
       "      <th>future_flare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.684222</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>1.193148</td>\n",
       "      <td>1.381086</td>\n",
       "      <td>2.121093</td>\n",
       "      <td>2.319864</td>\n",
       "      <td>2.192889</td>\n",
       "      <td>2.211154</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891687</td>\n",
       "      <td>1.617468</td>\n",
       "      <td>1.709285</td>\n",
       "      <td>2.375880</td>\n",
       "      <td>2.700176</td>\n",
       "      <td>2.971325</td>\n",
       "      <td>4.117771</td>\n",
       "      <td>4.067748</td>\n",
       "      <td>5.587491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.684222</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>1.193148</td>\n",
       "      <td>1.381086</td>\n",
       "      <td>2.121093</td>\n",
       "      <td>2.319864</td>\n",
       "      <td>2.192889</td>\n",
       "      <td>2.211154</td>\n",
       "      <td>1.596551</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617468</td>\n",
       "      <td>1.709285</td>\n",
       "      <td>2.375880</td>\n",
       "      <td>2.700176</td>\n",
       "      <td>2.971325</td>\n",
       "      <td>4.117771</td>\n",
       "      <td>4.067748</td>\n",
       "      <td>5.587491</td>\n",
       "      <td>6.042489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.684222</td>\n",
       "      <td>0.795803</td>\n",
       "      <td>1.193148</td>\n",
       "      <td>1.381086</td>\n",
       "      <td>2.121093</td>\n",
       "      <td>2.319864</td>\n",
       "      <td>2.192889</td>\n",
       "      <td>2.211154</td>\n",
       "      <td>1.596551</td>\n",
       "      <td>1.891687</td>\n",
       "      <td>...</td>\n",
       "      <td>1.709285</td>\n",
       "      <td>2.375880</td>\n",
       "      <td>2.700176</td>\n",
       "      <td>2.971325</td>\n",
       "      <td>4.117771</td>\n",
       "      <td>4.067748</td>\n",
       "      <td>5.587491</td>\n",
       "      <td>6.042489</td>\n",
       "      <td>7.320159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795803</td>\n",
       "      <td>1.193148</td>\n",
       "      <td>1.381086</td>\n",
       "      <td>2.121093</td>\n",
       "      <td>2.319864</td>\n",
       "      <td>2.192889</td>\n",
       "      <td>2.211154</td>\n",
       "      <td>1.596551</td>\n",
       "      <td>1.891687</td>\n",
       "      <td>1.617468</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375880</td>\n",
       "      <td>2.700176</td>\n",
       "      <td>2.971325</td>\n",
       "      <td>4.117771</td>\n",
       "      <td>4.067748</td>\n",
       "      <td>5.587491</td>\n",
       "      <td>6.042489</td>\n",
       "      <td>7.320159</td>\n",
       "      <td>6.653984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.193148</td>\n",
       "      <td>1.381086</td>\n",
       "      <td>2.121093</td>\n",
       "      <td>2.319864</td>\n",
       "      <td>2.192889</td>\n",
       "      <td>2.211154</td>\n",
       "      <td>1.596551</td>\n",
       "      <td>1.891687</td>\n",
       "      <td>1.617468</td>\n",
       "      <td>1.709285</td>\n",
       "      <td>...</td>\n",
       "      <td>2.700176</td>\n",
       "      <td>2.971325</td>\n",
       "      <td>4.117771</td>\n",
       "      <td>4.067748</td>\n",
       "      <td>5.587491</td>\n",
       "      <td>6.042489</td>\n",
       "      <td>7.320159</td>\n",
       "      <td>6.653984</td>\n",
       "      <td>7.411605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29395</th>\n",
       "      <td>1.382553</td>\n",
       "      <td>1.619027</td>\n",
       "      <td>1.818016</td>\n",
       "      <td>1.615437</td>\n",
       "      <td>1.476186</td>\n",
       "      <td>1.706824</td>\n",
       "      <td>1.586623</td>\n",
       "      <td>1.379842</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>1.346261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.426310</td>\n",
       "      <td>1.090913</td>\n",
       "      <td>1.017195</td>\n",
       "      <td>0.674936</td>\n",
       "      <td>0.518088</td>\n",
       "      <td>0.450388</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29396</th>\n",
       "      <td>1.619027</td>\n",
       "      <td>1.818016</td>\n",
       "      <td>1.615437</td>\n",
       "      <td>1.476186</td>\n",
       "      <td>1.706824</td>\n",
       "      <td>1.586623</td>\n",
       "      <td>1.379842</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>1.346261</td>\n",
       "      <td>1.490432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090913</td>\n",
       "      <td>1.017195</td>\n",
       "      <td>0.674936</td>\n",
       "      <td>0.518088</td>\n",
       "      <td>0.450388</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29397</th>\n",
       "      <td>1.818016</td>\n",
       "      <td>1.615437</td>\n",
       "      <td>1.476186</td>\n",
       "      <td>1.706824</td>\n",
       "      <td>1.586623</td>\n",
       "      <td>1.379842</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>1.346261</td>\n",
       "      <td>1.490432</td>\n",
       "      <td>1.426310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017195</td>\n",
       "      <td>0.674936</td>\n",
       "      <td>0.518088</td>\n",
       "      <td>0.450388</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.385925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29398</th>\n",
       "      <td>1.615437</td>\n",
       "      <td>1.476186</td>\n",
       "      <td>1.706824</td>\n",
       "      <td>1.586623</td>\n",
       "      <td>1.379842</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>1.346261</td>\n",
       "      <td>1.490432</td>\n",
       "      <td>1.426310</td>\n",
       "      <td>1.090913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674936</td>\n",
       "      <td>0.518088</td>\n",
       "      <td>0.450388</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.385925</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29399</th>\n",
       "      <td>1.476186</td>\n",
       "      <td>1.706824</td>\n",
       "      <td>1.586623</td>\n",
       "      <td>1.379842</td>\n",
       "      <td>1.332406</td>\n",
       "      <td>1.346261</td>\n",
       "      <td>1.490432</td>\n",
       "      <td>1.426310</td>\n",
       "      <td>1.090913</td>\n",
       "      <td>1.017195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518088</td>\n",
       "      <td>0.450388</td>\n",
       "      <td>0.344671</td>\n",
       "      <td>0.211968</td>\n",
       "      <td>0.254257</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>0.385925</td>\n",
       "      <td>0.303866</td>\n",
       "      <td>0.343112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29400 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            t_0       t_1       t_2       t_3       t_4       t_5       t_6  \\\n",
       "0      1.000000  0.975000  0.684222  0.795803  1.193148  1.381086  2.121093   \n",
       "1      0.975000  0.684222  0.795803  1.193148  1.381086  2.121093  2.319864   \n",
       "2      0.684222  0.795803  1.193148  1.381086  2.121093  2.319864  2.192889   \n",
       "3      0.795803  1.193148  1.381086  2.121093  2.319864  2.192889  2.211154   \n",
       "4      1.193148  1.381086  2.121093  2.319864  2.192889  2.211154  1.596551   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29395  1.382553  1.619027  1.818016  1.615437  1.476186  1.706824  1.586623   \n",
       "29396  1.619027  1.818016  1.615437  1.476186  1.706824  1.586623  1.379842   \n",
       "29397  1.818016  1.615437  1.476186  1.706824  1.586623  1.379842  1.332406   \n",
       "29398  1.615437  1.476186  1.706824  1.586623  1.379842  1.332406  1.346261   \n",
       "29399  1.476186  1.706824  1.586623  1.379842  1.332406  1.346261  1.490432   \n",
       "\n",
       "            t_7       t_8       t_9  ...      t_11      t_12      t_13  \\\n",
       "0      2.319864  2.192889  2.211154  ...  1.891687  1.617468  1.709285   \n",
       "1      2.192889  2.211154  1.596551  ...  1.617468  1.709285  2.375880   \n",
       "2      2.211154  1.596551  1.891687  ...  1.709285  2.375880  2.700176   \n",
       "3      1.596551  1.891687  1.617468  ...  2.375880  2.700176  2.971325   \n",
       "4      1.891687  1.617468  1.709285  ...  2.700176  2.971325  4.117771   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "29395  1.379842  1.332406  1.346261  ...  1.426310  1.090913  1.017195   \n",
       "29396  1.332406  1.346261  1.490432  ...  1.090913  1.017195  0.674936   \n",
       "29397  1.346261  1.490432  1.426310  ...  1.017195  0.674936  0.518088   \n",
       "29398  1.490432  1.426310  1.090913  ...  0.674936  0.518088  0.450388   \n",
       "29399  1.426310  1.090913  1.017195  ...  0.518088  0.450388  0.344671   \n",
       "\n",
       "           t_14      t_15      t_16      t_17      t_18      t_19  \\\n",
       "0      2.375880  2.700176  2.971325  4.117771  4.067748  5.587491   \n",
       "1      2.700176  2.971325  4.117771  4.067748  5.587491  6.042489   \n",
       "2      2.971325  4.117771  4.067748  5.587491  6.042489  7.320159   \n",
       "3      4.117771  4.067748  5.587491  6.042489  7.320159  6.653984   \n",
       "4      4.067748  5.587491  6.042489  7.320159  6.653984  7.411605   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "29395  0.674936  0.518088  0.450388  0.344671  0.211968  0.254257   \n",
       "29396  0.518088  0.450388  0.344671  0.211968  0.254257  0.336662   \n",
       "29397  0.450388  0.344671  0.211968  0.254257  0.336662  0.385925   \n",
       "29398  0.344671  0.211968  0.254257  0.336662  0.385925  0.303866   \n",
       "29399  0.211968  0.254257  0.336662  0.385925  0.303866  0.343112   \n",
       "\n",
       "       future_flare  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "29395             1  \n",
       "29396             1  \n",
       "29397             1  \n",
       "29398             1  \n",
       "29399             1  \n",
       "\n",
       "[29400 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    42598\n",
      "1     5422\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    18277\n",
      "1     2303\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    25843\n",
      "1     3557\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Total:\n",
      "0    86718\n",
      "1    11282\n",
      "Name: future_flare, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "print('Training set:')\n",
    "train_counts = df_train['future_flare'].value_counts()\n",
    "print(train_counts, '\\n')\n",
    "print('validation set:')\n",
    "val_counts = df_val['future_flare'].value_counts()\n",
    "print(val_counts, '\\n')\n",
    "print('Test set:')\n",
    "test_counts = df_test['future_flare'].value_counts()\n",
    "print(test_counts, '\\n')\n",
    "print('Total:')\n",
    "total_counts = train_counts.add(val_counts).add(test_counts)\n",
    "print(total_counts, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ## Train: (48020, 20) Val: (20580, 20) Test: (29400, 20) Total (98000, 20)\n",
      "y ## Train: (48020,)     Val: (20580,)     Test: (29400,)     Total (98000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "X_train_val, y_train_val = np.vstack((X_train, X_val)), np.hstack((y_train, y_val))\n",
    "X, y = np.vstack((X_train, X_val, X_test)), np.hstack((y_train, y_val, y_test))\n",
    "print('X ## Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape, 'Total', X.shape)\n",
    "print('y ## Train:', y_train.shape, '    Val:', y_val.shape, '    Test:', y_test.shape, '    Total', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10f6eWyl-Kq1"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCcYSR-z-M3Q"
   },
   "source": [
    "### Crossvalidation of simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbls = ['dt', 'nb', 'lp', 'svc', 'knn']\n",
    "\n",
    "class_weights = {0: 1, 1: 5}\n",
    "\n",
    "# Set the parameters to be explored by the grid for each classifier\n",
    "tuned_param_dt = [{'max_depth': list(range(1,20))}]\n",
    "tuned_param_nb = [{'var_smoothing': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-07, 1e-8, 1e-9, 1e-10]}]\n",
    "tuned_param_lp = [{'early_stopping': [True]}]\n",
    "tuned_param_svc = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000], 'class_weight':[class_weights]},\n",
    "                   \n",
    "                   \n",
    "                   {'kernel': ['linear'], 'C': [1, 10, 100, 1000], 'class_weight':[class_weights]}]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "\n",
    "# set the models to be fitted specifying name, estimator and parameter structure\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree       ',\n",
    "           'estimator': DecisionTreeClassifier(), \n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'nb': {'name': 'Gaussian Naive Bayes',\n",
    "           'estimator': GaussianNB(),\n",
    "           'param': tuned_param_nb\n",
    "          },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "           'estimator': Perceptron(),\n",
    "           'param': tuned_param_lp,\n",
    "          },\n",
    "    'svc':{'name': 'Support Vector      ',\n",
    "           'estimator': SVC(), \n",
    "           'param': tuned_param_svc\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "          }\n",
    "}\n",
    "\n",
    "# scores to be explored\n",
    "scores = ['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train_val set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train_val set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train_val set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "    print('AUC: 'metrics.auc(fpr, tpr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Decision Tree       \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'max_depth': 1}\n",
      "\n",
      "Grid scores on train_val set:\n",
      "\n",
      "0.747 (+/-0.018) for {'max_depth': 1}\n",
      "0.747 (+/-0.018) for {'max_depth': 2}\n",
      "0.745 (+/-0.018) for {'max_depth': 3}\n",
      "0.735 (+/-0.014) for {'max_depth': 4}\n",
      "0.736 (+/-0.015) for {'max_depth': 5}\n",
      "0.730 (+/-0.011) for {'max_depth': 6}\n",
      "0.726 (+/-0.018) for {'max_depth': 7}\n",
      "0.732 (+/-0.028) for {'max_depth': 8}\n",
      "0.726 (+/-0.021) for {'max_depth': 9}\n",
      "0.722 (+/-0.016) for {'max_depth': 10}\n",
      "0.726 (+/-0.022) for {'max_depth': 11}\n",
      "0.713 (+/-0.023) for {'max_depth': 12}\n",
      "0.714 (+/-0.027) for {'max_depth': 13}\n",
      "0.711 (+/-0.028) for {'max_depth': 14}\n",
      "0.709 (+/-0.026) for {'max_depth': 15}\n",
      "0.713 (+/-0.028) for {'max_depth': 16}\n",
      "0.711 (+/-0.024) for {'max_depth': 17}\n",
      "0.706 (+/-0.024) for {'max_depth': 18}\n",
      "0.704 (+/-0.026) for {'max_depth': 19}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train_val set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      1498\n",
      "           1       0.79      0.40      0.54       302\n",
      "\n",
      "    accuracy                           0.88      1800\n",
      "   macro avg       0.84      0.69      0.73      1800\n",
      "weighted avg       0.87      0.88      0.87      1800\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Gaussian Naive Bayes\n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'var_smoothing': 1e-07}\n",
      "\n",
      "Grid scores on train_val set:\n",
      "\n",
      "0.458 (+/-0.012) for {'var_smoothing': 10}\n",
      "0.462 (+/-0.017) for {'var_smoothing': 1}\n",
      "0.471 (+/-0.026) for {'var_smoothing': 0.1}\n",
      "0.501 (+/-0.030) for {'var_smoothing': 0.01}\n",
      "0.550 (+/-0.028) for {'var_smoothing': 0.001}\n",
      "0.615 (+/-0.024) for {'var_smoothing': 0.0001}\n",
      "0.666 (+/-0.038) for {'var_smoothing': 1e-05}\n",
      "0.676 (+/-0.029) for {'var_smoothing': 1e-06}\n",
      "0.677 (+/-0.030) for {'var_smoothing': 1e-07}\n",
      "0.677 (+/-0.030) for {'var_smoothing': 1e-08}\n",
      "0.677 (+/-0.030) for {'var_smoothing': 1e-09}\n",
      "0.677 (+/-0.030) for {'var_smoothing': 1e-10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train_val set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      1498\n",
      "           1       0.82      0.28      0.42       302\n",
      "\n",
      "    accuracy                           0.87      1800\n",
      "   macro avg       0.85      0.63      0.67      1800\n",
      "weighted avg       0.86      0.87      0.84      1800\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Linear Perceptron   \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'early_stopping': True}\n",
      "\n",
      "Grid scores on train_val set:\n",
      "\n",
      "0.683 (+/-0.154) for {'early_stopping': True}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train_val set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1498\n",
      "           1       0.43      0.37      0.40       302\n",
      "\n",
      "    accuracy                           0.81      1800\n",
      "   macro avg       0.65      0.64      0.64      1800\n",
      "weighted avg       0.80      0.81      0.81      1800\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model Support Vector      \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on train_val set:\n",
      "\n",
      "0.693 (+/-0.025) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.646 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.023) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.702 (+/-0.018) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.722 (+/-0.024) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.723 (+/-0.018) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.725 (+/-0.018) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.722 (+/-0.020) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.729 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.730 (+/-0.017) for {'C': 10, 'kernel': 'linear'}\n",
      "0.729 (+/-0.018) for {'C': 100, 'kernel': 'linear'}\n",
      "0.731 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train_val set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93      1498\n",
      "           1       0.80      0.38      0.52       302\n",
      "\n",
      "    accuracy                           0.88      1800\n",
      "   macro avg       0.85      0.68      0.72      1800\n",
      "weighted avg       0.87      0.88      0.86      1800\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Trying model K Nearest Neighbor \n",
      "Best parameters set found on train set:\n",
      "\n",
      "{'n_neighbors': 7}\n",
      "\n",
      "Grid scores on train_val set:\n",
      "\n",
      "0.652 (+/-0.031) for {'n_neighbors': 1}\n",
      "0.657 (+/-0.030) for {'n_neighbors': 2}\n",
      "0.694 (+/-0.028) for {'n_neighbors': 3}\n",
      "0.682 (+/-0.033) for {'n_neighbors': 4}\n",
      "0.705 (+/-0.030) for {'n_neighbors': 5}\n",
      "0.697 (+/-0.030) for {'n_neighbors': 6}\n",
      "0.706 (+/-0.033) for {'n_neighbors': 7}\n",
      "0.698 (+/-0.031) for {'n_neighbors': 8}\n",
      "0.706 (+/-0.026) for {'n_neighbors': 9}\n",
      "0.698 (+/-0.026) for {'n_neighbors': 10}\n",
      "\n",
      "Detailed classification report for the best parameter set:\n",
      "\n",
      "The model is trained on the full train_val set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      1498\n",
      "           1       0.74      0.35      0.48       302\n",
      "\n",
      "    accuracy                           0.87      1800\n",
      "   macro avg       0.81      0.66      0.70      1800\n",
      "weighted avg       0.86      0.87      0.85      1800\n",
      "\n",
      "\n",
      "Summary of results for f1\n",
      "Estimator\n",
      "Decision Tree       \t - score: 74.67%\n",
      "Gaussian Naive Bayes\t - score: 67.73%\n",
      "Linear Perceptron   \t - score: 68.31%\n",
      "Support Vector      \t - score: 73.14%\n",
      "K Nearest Neighbor \t - score: 70.63%\n"
     ]
    }
   ],
   "source": [
    "results_short = {}\n",
    "cv_results = []\n",
    "for score in scores:\n",
    "    print('='*40)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    s_result = []\n",
    "    for m in model_lbls:\n",
    "        print('-'*40)\n",
    "        print(\"Trying model {}\".format(models[m]['name']))\n",
    "        clf = GridSearchCV(models[m]['estimator'], models[m]['param'], cv=5,\n",
    "                           scoring='%s_macro' % score,\n",
    "                           return_train_score = False,\n",
    "                           n_jobs = 2, # this allows using multi-cores\n",
    "                           )\n",
    "        clf.fit(X_train_val, y_train_val)\n",
    "        print_results(clf)\n",
    "        s_result.append(clf)\n",
    "        results_short[m] = clf.best_score_\n",
    "    cv_results.append(s_result)\n",
    "    print(\"Summary of results for {}\".format(score))\n",
    "    print(\"Estimator\")\n",
    "    for m in results_short.keys():\n",
    "        print(\"{}\\t - score: {:5.2f}%\".format(models[m]['name'], results_short[m]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(len(cv_results)):\n",
    "    s_result = cv_results[s]\n",
    "    for m in range(len(s_result)):\n",
    "        clf = cv_results[s][m]\n",
    "        joblib.dump(clf, os.path.join(\"models\", f\"{scores[s]}_{model_lbls[m]}.pkl\"))\n",
    "        \n",
    "        \n",
    "#load your model for further usage\n",
    "# clf = joblib.load(\"model_file_name.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train_cnn = scaler.transform(X_train)\n",
    "X_val_cnn = scaler.transform(X_val)\n",
    "X_test_cnn = scaler.transform(X_test)\n",
    "# Make the data uniform to multivariate timeseries\n",
    "X_train_cnn = X_train_cnn.reshape((X_train_cnn.shape[0], X_train_cnn.shape[1], 1))\n",
    "X_val_cnn = X_val_cnn.reshape((X_val_cnn.shape[0], X_val_cnn.shape[1], 1))\n",
    "X_test_cnn = X_test_cnn.reshape((X_test_cnn.shape[0], X_test_cnn.shape[1], 1))\n",
    "# get automatically the number of classes\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 64)           256       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 100, 64)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 18:28:17.639332: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-16 18:28:17.639396: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-16 18:28:17.639422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5166cf34c918): /proc/driver/nvidia/version does not exist\n",
      "2023-03-16 18:28:17.639711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re_lu_1 (ReLU)              (None, 100, 64)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 100, 64)           12352     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 100, 64)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,793\n",
      "Trainable params: 25,409\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape, num_classes, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "    if num_classes==2:\n",
    "        output_layer = keras.layers.Dense(1, activation=\"sigmoid\", bias_initializer=output_bias)(gap)\n",
    "    else:\n",
    "        output_layer = keras.layers.Dense(num_classes, activation=\"softmax\", bias_initializer=output_bias)(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "initial_bias = np.log([train_counts[1]/train_counts[0]])\n",
    "cnn_model = make_model(input_shape=X_train_cnn.shape[1:], num_classes=num_classes, output_bias=initial_bias)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "22/22 [==============================] - 7s 179ms/step - loss: 0.4262 - f1_m: 0.2508 - val_loss: 0.4326 - val_f1_m: 0.0484 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.4082 - f1_m: 0.2922 - val_loss: 0.4307 - val_f1_m: 0.0196 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.4008 - f1_m: 0.3244 - val_loss: 0.4320 - val_f1_m: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.4012 - f1_m: 0.3595 - val_loss: 0.4216 - val_f1_m: 0.0151 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.3910 - f1_m: 0.3562 - val_loss: 0.4212 - val_f1_m: 0.0196 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3852 - f1_m: 0.3661 - val_loss: 0.4213 - val_f1_m: 0.0251 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.3855 - f1_m: 0.3557 - val_loss: 0.4117 - val_f1_m: 0.0591 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3907 - f1_m: 0.3715 - val_loss: 0.4229 - val_f1_m: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.3805 - f1_m: 0.3891 - val_loss: 0.4131 - val_f1_m: 0.0153 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3756 - f1_m: 0.4209 - val_loss: 0.4143 - val_f1_m: 0.0830 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.3734 - f1_m: 0.4306 - val_loss: 0.4389 - val_f1_m: 0.1999 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.3787 - f1_m: 0.4154 - val_loss: 0.4646 - val_f1_m: 0.2562 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.3706 - f1_m: 0.4067 - val_loss: 0.4745 - val_f1_m: 0.3959 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.3746 - f1_m: 0.4114 - val_loss: 0.5033 - val_f1_m: 0.4360 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3774 - f1_m: 0.4308 - val_loss: 0.5154 - val_f1_m: 0.4359 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3661 - f1_m: 0.4221 - val_loss: 0.4767 - val_f1_m: 0.4283 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3660 - f1_m: 0.4537 - val_loss: 0.4813 - val_f1_m: 0.4334 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.3658 - f1_m: 0.4480 - val_loss: 0.4876 - val_f1_m: 0.4170 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3726 - f1_m: 0.4276 - val_loss: 0.5711 - val_f1_m: 0.4470 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.3725 - f1_m: 0.4264 - val_loss: 0.6015 - val_f1_m: 0.4885 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.3658 - f1_m: 0.4169 - val_loss: 0.4581 - val_f1_m: 0.1577 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3685 - f1_m: 0.4202 - val_loss: 0.4462 - val_f1_m: 0.4006 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.3645 - f1_m: 0.4684 - val_loss: 0.4528 - val_f1_m: 0.2585 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3566 - f1_m: 0.4730 - val_loss: 0.4760 - val_f1_m: 0.3737 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3528 - f1_m: 0.4831 - val_loss: 0.4817 - val_f1_m: 0.3286 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3535 - f1_m: 0.4843 - val_loss: 0.4858 - val_f1_m: 0.2904 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.3542 - f1_m: 0.4885 - val_loss: 0.3838 - val_f1_m: 0.2414 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3604 - f1_m: 0.4809 - val_loss: 0.4144 - val_f1_m: 0.2844 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 0.3597 - f1_m: 0.4670 - val_loss: 0.4147 - val_f1_m: 0.3890 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3588 - f1_m: 0.4886 - val_loss: 0.4962 - val_f1_m: 0.4126 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3536 - f1_m: 0.4809 - val_loss: 0.4108 - val_f1_m: 0.3369 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 0.3596 - f1_m: 0.4476 - val_loss: 0.4180 - val_f1_m: 0.0870 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 0.3680 - f1_m: 0.4544 - val_loss: 0.4033 - val_f1_m: 0.1887 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.3562 - f1_m: 0.4940 - val_loss: 0.4255 - val_f1_m: 0.1917 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 4s 193ms/step - loss: 0.3548 - f1_m: 0.4886 - val_loss: 0.3921 - val_f1_m: 0.3157 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 4s 194ms/step - loss: 0.3690 - f1_m: 0.4731 - val_loss: 0.5047 - val_f1_m: 0.2336 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.3625 - f1_m: 0.4427 - val_loss: 0.3833 - val_f1_m: 0.1181 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3531 - f1_m: 0.4883 - val_loss: 0.3857 - val_f1_m: 0.1323 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.3557 - f1_m: 0.5017 - val_loss: 0.3834 - val_f1_m: 0.2187 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.3569 - f1_m: 0.4795 - val_loss: 0.5181 - val_f1_m: 0.2256 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.3551 - f1_m: 0.4608 - val_loss: 0.4033 - val_f1_m: 0.2118 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.3525 - f1_m: 0.5020 - val_loss: 0.4330 - val_f1_m: 0.2206 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3543 - f1_m: 0.5084 - val_loss: 0.4693 - val_f1_m: 0.3128 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.3561 - f1_m: 0.4875 - val_loss: 0.4281 - val_f1_m: 0.3793 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.3528 - f1_m: 0.4921 - val_loss: 0.5048 - val_f1_m: 0.4289 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.3544 - f1_m: 0.5044 - val_loss: 0.4333 - val_f1_m: 0.2864 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.3485 - f1_m: 0.4894 - val_loss: 0.3963 - val_f1_m: 0.2271 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3520 - f1_m: 0.5075 - val_loss: 0.3899 - val_f1_m: 0.1104 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.3583 - f1_m: 0.4769 - val_loss: 0.3909 - val_f1_m: 0.2349 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.3550 - f1_m: 0.4733 - val_loss: 0.4282 - val_f1_m: 0.2816 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3530 - f1_m: 0.5042 - val_loss: 0.3902 - val_f1_m: 0.1892 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.3537 - f1_m: 0.5018 - val_loss: 0.4115 - val_f1_m: 0.3157 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.3512 - f1_m: 0.4969 - val_loss: 0.4387 - val_f1_m: 0.3022 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.3473 - f1_m: 0.5409 - val_loss: 0.3862 - val_f1_m: 0.2500 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.3525 - f1_m: 0.5031 - val_loss: 0.4269 - val_f1_m: 0.1873 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3494 - f1_m: 0.5009 - val_loss: 0.3989 - val_f1_m: 0.1826 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.3491 - f1_m: 0.4831 - val_loss: 0.4157 - val_f1_m: 0.1836 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.3482 - f1_m: 0.4902 - val_loss: 0.3765 - val_f1_m: 0.2240 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.3496 - f1_m: 0.5167 - val_loss: 0.4538 - val_f1_m: 0.2253 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 4s 189ms/step - loss: 0.3600 - f1_m: 0.4935 - val_loss: 0.3799 - val_f1_m: 0.2426 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.3582 - f1_m: 0.4719 - val_loss: 0.4062 - val_f1_m: 0.2297 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3484 - f1_m: 0.5031 - val_loss: 0.3998 - val_f1_m: 0.2269 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.3532 - f1_m: 0.4826 - val_loss: 0.3879 - val_f1_m: 0.1199 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.3471 - f1_m: 0.5180 - val_loss: 0.3866 - val_f1_m: 0.1407 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3494 - f1_m: 0.5006 - val_loss: 0.3889 - val_f1_m: 0.1564 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3535 - f1_m: 0.4904 - val_loss: 0.3788 - val_f1_m: 0.2463 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.3472 - f1_m: 0.4966 - val_loss: 0.3916 - val_f1_m: 0.1719 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.3534 - f1_m: 0.5068 - val_loss: 0.3914 - val_f1_m: 0.1906 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3454 - f1_m: 0.4976 - val_loss: 0.3851 - val_f1_m: 0.1424 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.3470 - f1_m: 0.5077 - val_loss: 0.3910 - val_f1_m: 0.0953 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.3487 - f1_m: 0.5018 - val_loss: 0.3853 - val_f1_m: 0.1672 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 4s 159ms/step - loss: 0.3533 - f1_m: 0.4991 - val_loss: 0.4230 - val_f1_m: 0.1695 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.3558 - f1_m: 0.4609 - val_loss: 0.3845 - val_f1_m: 0.1379 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.3503 - f1_m: 0.4923 - val_loss: 0.3826 - val_f1_m: 0.1760 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.3492 - f1_m: 0.5220 - val_loss: 0.3920 - val_f1_m: 0.1705 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.3482 - f1_m: 0.5069 - val_loss: 0.4399 - val_f1_m: 0.2093 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3475 - f1_m: 0.4990 - val_loss: 0.4049 - val_f1_m: 0.1745 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.3505 - f1_m: 0.5118 - val_loss: 0.3982 - val_f1_m: 0.1290 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3462 - f1_m: 0.4975 - val_loss: 0.3918 - val_f1_m: 0.1364 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3502 - f1_m: 0.5005 - val_loss: 0.3913 - val_f1_m: 0.2118 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3479 - f1_m: 0.4836 - val_loss: 0.3859 - val_f1_m: 0.2098 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.3517 - f1_m: 0.4930 - val_loss: 0.3703 - val_f1_m: 0.2452 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.3610 - f1_m: 0.4978 - val_loss: 0.3825 - val_f1_m: 0.2715 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.3551 - f1_m: 0.4973 - val_loss: 0.3781 - val_f1_m: 0.2201 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.3455 - f1_m: 0.4924 - val_loss: 0.3930 - val_f1_m: 0.1268 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 4s 196ms/step - loss: 0.3499 - f1_m: 0.4893 - val_loss: 0.3745 - val_f1_m: 0.1843 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.3542 - f1_m: 0.5048 - val_loss: 0.3852 - val_f1_m: 0.1732 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.3519 - f1_m: 0.4879 - val_loss: 0.3785 - val_f1_m: 0.1865 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.3527 - f1_m: 0.4876 - val_loss: 0.3751 - val_f1_m: 0.2196 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3496 - f1_m: 0.4795 - val_loss: 0.4000 - val_f1_m: 0.1816 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.3449 - f1_m: 0.5356 - val_loss: 0.3993 - val_f1_m: 0.1808 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.3421 - f1_m: 0.5194 - val_loss: 0.4239 - val_f1_m: 0.1453 - lr: 5.0000e-04\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3424 - f1_m: 0.5228 - val_loss: 0.4238 - val_f1_m: 0.2098 - lr: 5.0000e-04\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.3421 - f1_m: 0.4965 - val_loss: 0.4097 - val_f1_m: 0.1787 - lr: 5.0000e-04\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.3417 - f1_m: 0.5212 - val_loss: 0.4079 - val_f1_m: 0.1655 - lr: 5.0000e-04\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3438 - f1_m: 0.5251 - val_loss: 0.4402 - val_f1_m: 0.2413 - lr: 5.0000e-04\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3410 - f1_m: 0.5240 - val_loss: 0.4328 - val_f1_m: 0.2449 - lr: 5.0000e-04\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3424 - f1_m: 0.5311 - val_loss: 0.4263 - val_f1_m: 0.1929 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.3405 - f1_m: 0.5009 - val_loss: 0.4175 - val_f1_m: 0.1655 - lr: 5.0000e-04\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.3472 - f1_m: 0.5174 - val_loss: 0.4179 - val_f1_m: 0.1621 - lr: 5.0000e-04\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3423 - f1_m: 0.5282 - val_loss: 0.4312 - val_f1_m: 0.1829 - lr: 5.0000e-04\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3395 - f1_m: 0.5311 - val_loss: 0.4172 - val_f1_m: 0.1864 - lr: 5.0000e-04\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3423 - f1_m: 0.5179 - val_loss: 0.4357 - val_f1_m: 0.1977 - lr: 5.0000e-04\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.3435 - f1_m: 0.5292 - val_loss: 0.4038 - val_f1_m: 0.1847 - lr: 5.0000e-04\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.3445 - f1_m: 0.5463 - val_loss: 0.4051 - val_f1_m: 0.2228 - lr: 5.0000e-04\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.3443 - f1_m: 0.5020 - val_loss: 0.4088 - val_f1_m: 0.2418 - lr: 5.0000e-04\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.3445 - f1_m: 0.5142 - val_loss: 0.4108 - val_f1_m: 0.1720 - lr: 5.0000e-04\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.3455 - f1_m: 0.5281 - val_loss: 0.4192 - val_f1_m: 0.1962 - lr: 5.0000e-04\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.3414 - f1_m: 0.5173 - val_loss: 0.4365 - val_f1_m: 0.1789 - lr: 5.0000e-04\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 3s 135ms/step - loss: 0.3458 - f1_m: 0.5161 - val_loss: 0.4078 - val_f1_m: 0.1720 - lr: 5.0000e-04\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3422 - f1_m: 0.5257 - val_loss: 0.4093 - val_f1_m: 0.1756 - lr: 5.0000e-04\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 3s 133ms/step - loss: 0.3445 - f1_m: 0.4808 - val_loss: 0.4303 - val_f1_m: 0.1738 - lr: 5.0000e-04\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.3465 - f1_m: 0.5223 - val_loss: 0.4409 - val_f1_m: 0.1944 - lr: 5.0000e-04\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 3s 144ms/step - loss: 0.3416 - f1_m: 0.5285 - val_loss: 0.4379 - val_f1_m: 0.2390 - lr: 5.0000e-04\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3420 - f1_m: 0.5408 - val_loss: 0.4336 - val_f1_m: 0.2608 - lr: 5.0000e-04\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.3433 - f1_m: 0.5329 - val_loss: 0.4487 - val_f1_m: 0.1898 - lr: 5.0000e-04\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 3s 142ms/step - loss: 0.3391 - f1_m: 0.5444 - val_loss: 0.4128 - val_f1_m: 0.1980 - lr: 5.0000e-04\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.3420 - f1_m: 0.4966 - val_loss: 0.4201 - val_f1_m: 0.1910 - lr: 5.0000e-04\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.3410 - f1_m: 0.5152 - val_loss: 0.4243 - val_f1_m: 0.1578 - lr: 5.0000e-04\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.3403 - f1_m: 0.5446 - val_loss: 0.4203 - val_f1_m: 0.1100 - lr: 5.0000e-04\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.3400 - f1_m: 0.5157 - val_loss: 0.4059 - val_f1_m: 0.1344 - lr: 5.0000e-04\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.3411 - f1_m: 0.5187 - val_loss: 0.4092 - val_f1_m: 0.1008 - lr: 5.0000e-04\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 5s 212ms/step - loss: 0.3442 - f1_m: 0.5111 - val_loss: 0.4129 - val_f1_m: 0.1158 - lr: 5.0000e-04\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 4s 154ms/step - loss: 0.3432 - f1_m: 0.5300 - val_loss: 0.3971 - val_f1_m: 0.1344 - lr: 5.0000e-04\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.3439 - f1_m: 0.5227 - val_loss: 0.4021 - val_f1_m: 0.1489 - lr: 5.0000e-04\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 3s 160ms/step - loss: 0.3431 - f1_m: 0.5110 - val_loss: 0.4103 - val_f1_m: 0.1688 - lr: 5.0000e-04\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3410 - f1_m: 0.5314 - val_loss: 0.4011 - val_f1_m: 0.1980 - lr: 5.0000e-04\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.3399 - f1_m: 0.5110 - val_loss: 0.4169 - val_f1_m: 0.1542 - lr: 5.0000e-04\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.3405 - f1_m: 0.5290 - val_loss: 0.4111 - val_f1_m: 0.1435 - lr: 5.0000e-04\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.3395 - f1_m: 0.5257 - val_loss: 0.4086 - val_f1_m: 0.1252 - lr: 5.0000e-04\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 3s 149ms/step - loss: 0.3484 - f1_m: 0.4803 - val_loss: 0.4144 - val_f1_m: 0.1435 - lr: 5.0000e-04\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 4s 158ms/step - loss: 0.3364 - f1_m: 0.5475 - val_loss: 0.4082 - val_f1_m: 0.1580 - lr: 5.0000e-04\n",
      "Epoch 132: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 256\n",
    "cnn_path = os.path.join(\"models\", \"CNN_best_weights.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(cnn_path, save_weights_only=True, monitor=\"val_loss\"),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=20, min_lr=0.0001),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1)\n",
    "]\n",
    "if num_classes==2:\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "else:\n",
    "    loss = \"sparse_categorical_crossentropy\"\n",
    "cnn_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=loss,\n",
    "    metrics=[f1_m],\n",
    ")\n",
    "cnn_history = cnn_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(cnn_history.history[metric])\n",
    "plt.plot(cnn_history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 8ms/step\n",
      "Test F1 Macro 0.461069238630557\n"
     ]
    }
   ],
   "source": [
    "cnn_model = make_model(input_shape=X_train_cnn.shape[1:], num_classes=num_classes, output_bias=initial_bias)\n",
    "cnn_model.load_weights(cnn_path)\n",
    "y_test_pred_cnn = np.round(cnn_model.predict(X_test_cnn), 0)\n",
    "test_f1_macro_cnn = f1_score(y_test, y_test_pred_cnn, average='macro')\n",
    "print(\"Test F1 Macro\", test_f1_macro_cnn)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_test_pred_cnn, pos_label=1)\n",
    "print('AUC: 'metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY415R-r-OkG"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 40)               3520      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "def make_lstm(input_shape, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=input_shape))\n",
    "    lstm_model.add(Dense(30, activation='relu'))\n",
    "    lstm_model.add(Dense(10, activation='relu'))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid',bias_initializer=output_bias))\n",
    "    return lstm_model\n",
    "\n",
    "initial_bias = np.log([train_counts[1]/train_counts[0]])\n",
    "lstm_model = make_lstm((X_train_cnn.shape[1], 1), output_bias=initial_bias)\n",
    "lstm_model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1_m, 'accuracy'])\n",
    "\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1501/1501 [==============================] - 23s 13ms/step - loss: 0.0488 - f1_m: 0.8335 - accuracy: 0.9831 - val_loss: 0.0322 - val_f1_m: 0.0986 - val_accuracy: 0.9843\n",
      "Epoch 2/20\n",
      "1501/1501 [==============================] - 18s 12ms/step - loss: 0.0253 - f1_m: 0.8892 - accuracy: 0.9900 - val_loss: 0.0221 - val_f1_m: 0.1185 - val_accuracy: 0.9919\n",
      "Epoch 3/20\n",
      "1501/1501 [==============================] - 18s 12ms/step - loss: 0.0210 - f1_m: 0.9122 - accuracy: 0.9919 - val_loss: 0.0189 - val_f1_m: 0.1150 - val_accuracy: 0.9919\n",
      "Epoch 4/20\n",
      "1501/1501 [==============================] - 18s 12ms/step - loss: 0.0176 - f1_m: 0.9195 - accuracy: 0.9930 - val_loss: 0.0171 - val_f1_m: 0.1181 - val_accuracy: 0.9930\n",
      "Epoch 5/20\n",
      "1501/1501 [==============================] - 18s 12ms/step - loss: 0.0156 - f1_m: 0.9205 - accuracy: 0.9938 - val_loss: 0.0138 - val_f1_m: 0.1164 - val_accuracy: 0.9942\n",
      "Epoch 6/20\n",
      "1501/1501 [==============================] - 19s 12ms/step - loss: 0.0143 - f1_m: 0.9182 - accuracy: 0.9944 - val_loss: 0.0132 - val_f1_m: 0.1157 - val_accuracy: 0.9950\n",
      "Epoch 7/20\n",
      "1501/1501 [==============================] - 19s 13ms/step - loss: 0.0131 - f1_m: 0.9198 - accuracy: 0.9947 - val_loss: 0.0147 - val_f1_m: 0.1192 - val_accuracy: 0.9935\n",
      "Epoch 8/20\n",
      "1501/1501 [==============================] - 20s 14ms/step - loss: 0.0122 - f1_m: 0.9274 - accuracy: 0.9954 - val_loss: 0.0104 - val_f1_m: 0.1189 - val_accuracy: 0.9964\n",
      "Epoch 9/20\n",
      "1501/1501 [==============================] - 21s 14ms/step - loss: 0.0111 - f1_m: 0.9273 - accuracy: 0.9960 - val_loss: 0.0087 - val_f1_m: 0.1193 - val_accuracy: 0.9974\n",
      "Epoch 10/20\n",
      "1501/1501 [==============================] - 19s 13ms/step - loss: 0.0100 - f1_m: 0.9316 - accuracy: 0.9964 - val_loss: 0.0089 - val_f1_m: 0.1179 - val_accuracy: 0.9967\n",
      "Epoch 11/20\n",
      "1501/1501 [==============================] - 20s 13ms/step - loss: 0.0093 - f1_m: 0.9288 - accuracy: 0.9966 - val_loss: 0.0083 - val_f1_m: 0.1196 - val_accuracy: 0.9968\n",
      "Epoch 12/20\n",
      "1501/1501 [==============================] - 24s 16ms/step - loss: 0.0084 - f1_m: 0.9363 - accuracy: 0.9970 - val_loss: 0.0089 - val_f1_m: 0.1208 - val_accuracy: 0.9963\n",
      "Epoch 13/20\n",
      "1501/1501 [==============================] - 19s 13ms/step - loss: 0.0083 - f1_m: 0.9384 - accuracy: 0.9972 - val_loss: 0.0093 - val_f1_m: 0.1189 - val_accuracy: 0.9963\n",
      "Epoch 14/20\n",
      "1501/1501 [==============================] - 19s 12ms/step - loss: 0.0091 - f1_m: 0.9423 - accuracy: 0.9968 - val_loss: 0.0102 - val_f1_m: 0.1204 - val_accuracy: 0.9955\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "lstm_path = os.path.join(\"models\", \"LSTM_best_weights.h5\")\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(lstm_path, save_weights_only=True, monitor=\"val_loss\"),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "lstm_history = lstm_model.fit(\n",
    "    X_train_cnn,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = \"loss\"\n",
    "plt.figure()\n",
    "plt.plot(lstm_history.history[metric])\n",
    "plt.plot(lstm_history.history[\"val_\" + metric])\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919/919 [==============================] - 4s 4ms/step\n",
      "### Evaluation on test set ###\n",
      "Accuracy: 1.00\n",
      "F1 Macro score: 0.99\n",
      "[[26431    50]\n",
      " [   40  2879]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model = make_lstm((X_train_cnn.shape[1], 1))\n",
    "lstm_model.load_weights(lstm_path)\n",
    "y_test_pred_lstm = np.round(lstm_model.predict(X_test_cnn), 0)\n",
    "\n",
    "print(\"### Evaluation on test set ###\")\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_test, y_test_pred_lstm, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_test_pred_lstm)\n",
    "print(result)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_test_pred_lstm, pos_label=1)\n",
    "print('AUC: 'metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P15_tKow_ZEO"
   },
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7RuDDpA_lCv"
   },
   "source": [
    "### Interpolation vs Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of data is important when making predictions. If data points are missing from a data range, interpolation and extrapolation are used to predict the values that are in the missing range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 64.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30, 1, 4, 1, 1, 1000), (30, 1, 4, 1, 1, 1000))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize data loader\n",
    "data_loader = DataLoader(run=30, N=1000, s=0.5, t=[0.01, 0.1, 0.5, 3], d=0.2, m=1, override=True)\n",
    "# get the grid\n",
    "grid_X, grid_y = data_loader.get_grid()\n",
    "# get params dictionary\n",
    "params = data_loader.get_params()\n",
    "\n",
    "grid_X.shape, grid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM model with multiple all theta parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start seeing what is going to happen with training and testing the NN with all the configurations of theta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54880, 21), (27440, 21), (35280, 21))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train,df_val,df_test = get_dataset_split(grid_X, grid_y, None, window_size=20, overlap_size=19,\n",
    "                                            label_treshold=1, split_on_run=True, shuffle_run=False, \n",
    "                                            shuffle_window=False, test_size = 0.3, val_size=0.2, \n",
    "                                            get_validation=True, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell shows the amounts of class 0 and 1 for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0    35219\n",
      "1    19661\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "validation set:\n",
      "0    17576\n",
      "1     9864\n",
      "Name: future_flare, dtype: int64 \n",
      "\n",
      "Test set:\n",
      "0    22742\n",
      "1    12538\n",
      "Name: future_flare, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "print('Training set:')\n",
    "print(df_train['future_flare'].value_counts(), '\\n')\n",
    "pos = df_train['future_flare'].value_counts()[0]\n",
    "true = df_train['future_flare'].value_counts()[1]\n",
    "print('validation set:')\n",
    "print(df_val['future_flare'].value_counts(), '\\n')\n",
    "print('Test set:')\n",
    "print(df_test['future_flare'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ## Train: (54880, 20) Val: (27440, 20) Test: (35280, 20)\n",
      "y ## Train: (54880,) Val: (27440,) Test: (35280,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "X = np.vstack((X_train, X_val, X_test))\n",
    "y = np.hstack((y_train, y_val, y_test))\n",
    "print('X ## Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n",
    "print('y ## Train:', y_train.shape, 'Val:', y_val.shape, 'Test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct now the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 40)               3520      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,071\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "initial_bias = Constant([np.log(true/pos)])\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid',bias_initializer=initial_bias))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1_m, 'accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1715/1715 [==============================] - 23s 12ms/step - loss: 0.2067 - f1_m: 0.8705 - accuracy: 0.9149 - val_loss: 0.2099 - val_f1_m: 0.4946 - val_accuracy: 0.9061\n",
      "Epoch 2/20\n",
      "1715/1715 [==============================] - 19s 11ms/step - loss: 0.1292 - f1_m: 0.9205 - accuracy: 0.9470 - val_loss: 0.0900 - val_f1_m: 0.5140 - val_accuracy: 0.9653\n",
      "Epoch 3/20\n",
      "1715/1715 [==============================] - 19s 11ms/step - loss: 0.0963 - f1_m: 0.9427 - accuracy: 0.9612 - val_loss: 0.0855 - val_f1_m: 0.5072 - val_accuracy: 0.9638\n",
      "Epoch 4/20\n",
      "1715/1715 [==============================] - 19s 11ms/step - loss: 0.0808 - f1_m: 0.9545 - accuracy: 0.9691 - val_loss: 0.0639 - val_f1_m: 0.5246 - val_accuracy: 0.9789\n",
      "Epoch 5/20\n",
      "1715/1715 [==============================] - 19s 11ms/step - loss: 0.0723 - f1_m: 0.9601 - accuracy: 0.9726 - val_loss: 0.0851 - val_f1_m: 0.5033 - val_accuracy: 0.9644\n",
      "Epoch 6/20\n",
      "1715/1715 [==============================] - 19s 11ms/step - loss: 0.0660 - f1_m: 0.9629 - accuracy: 0.9750 - val_loss: 0.0548 - val_f1_m: 0.5260 - val_accuracy: 0.9823\n",
      "Epoch 7/20\n",
      "1091/1715 [==================>...........] - ETA: 5s - loss: 0.0644 - f1_m: 0.9644 - accuracy: 0.9763"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_allTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "y_pred = np.round(model.predict(X_val), 0)\n",
    "\n",
    "print(\"### Evaluation on validation set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_val)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_val, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_val, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred = np.round(model.predict(X_test), 0)\n",
    "\n",
    "print(\"### Evaluation on test set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_test)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_test, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before, but now we are fitting only in the dataset coming from the generation with using just the extreme parameters: \n",
    "\n",
    "$\\theta=0.01$ and $\\theta=3$\n",
    "\n",
    "and a fraction of the other dataset, coming from $\\theta=0.1$ and $\\theta=0.5$ as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'theta'\n",
    "theta_train_list     = [0.01, 3]\n",
    "theta_train_list_idx = [params[p].index(t) for t in theta_train_list]\n",
    "theta_test_list      = [0.1, 0.5]\n",
    "theta_test_list_idx  = [params[p].index(t) for t in theta_test_list]\n",
    "\n",
    "# get the train and validation set, selecting the index for grid given the interpolation assuption\n",
    "# notice that theta is the third parameter\n",
    "df_train, df_val, _ = get_dataset_split(grid_X[:,:,theta_train_list_idx,:,:,:], \n",
    "                                        grid_y[:,:,theta_train_list_idx,:,:,:], \n",
    "                                        None, window_size=20, overlap_size=19,\n",
    "                                        label_treshold=1, split_on_run=True, shuffle_run=False, \n",
    "                                        shuffle_window=False, test_size = 0.3, val_size=0.2, \n",
    "                                        get_validation=True, random_state=42)\n",
    "# get the test set, selecting the index for grid given the interpolation assuption\n",
    "# notice that theta is the third parameter\n",
    "_, _, df_test = get_dataset_split(grid_X[:,:,theta_test_list_idx,:,:,:], \n",
    "                                  grid_y[:,:,theta_test_list_idx,:,:,:], \n",
    "                                  None, window_size=20, overlap_size=19,\n",
    "                                  label_treshold=1, split_on_run=True, shuffle_run=False, \n",
    "                                  shuffle_window=False, test_size = 0.3, val_size=0.2, \n",
    "                                  get_validation=True, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of classes\n",
    "print('Training set:')\n",
    "print(df_train['future_flare'].value_counts(), '\\n')\n",
    "pos = df_train['future_flare'].value_counts()[0]\n",
    "true = df_train['future_flare'].value_counts()[1]\n",
    "print('validation set:')\n",
    "print(df_val['future_flare'].value_counts(), '\\n')\n",
    "print('Test set:')\n",
    "print(df_test['future_flare'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "X = np.vstack((X_train, X_val, X_test))\n",
    "y = np.hstack((y_train, y_val, y_test))\n",
    "print('X ## Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n",
    "print('y ## Train:', y_train.shape, 'Val:', y_val.shape, 'Test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = Constant([np.log(true/pos)])\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid',bias_initializer=initial_bias))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1_m, 'accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_intrpTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "y_pred = np.round(model.predict(X_val), 0)\n",
    "\n",
    "print(\"### Evaluation on validation set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_val)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_val, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_val, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred = np.round(model.predict(X_test), 0)\n",
    "\n",
    "print(\"### Evaluation on test set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_test)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_test, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are still similar to the standard case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrapolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before, but now we are fitting only in the dataset coming from the generation without using the extreme parameters: \n",
    "\n",
    "$\\theta=0.1$ and $\\theta=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'theta'\n",
    "theta_train_list     = [0.1, 0.5]\n",
    "theta_train_list_idx = [params[p].index(t) for t in theta_train_list]\n",
    "theta_test_list      = [0.01, 3]\n",
    "theta_test_list_idx  = [params[p].index(t) for t in theta_test_list]\n",
    "\n",
    "# get the train and validation set, selecting the index for grid given the interpolation assuption\n",
    "# notice that theta is the third parameter\n",
    "df_train, df_val, _ = get_dataset_split(grid_X[:,:,theta_train_list_idx,:,:,:], \n",
    "                                        grid_y[:,:,theta_train_list_idx,:,:,:], \n",
    "                                        None, window_size=20, overlap_size=19,\n",
    "                                        label_treshold=1, split_on_run=True, shuffle_run=False, \n",
    "                                        shuffle_window=False, test_size = 0.3, val_size=0.2, \n",
    "                                        get_validation=True, random_state=42)\n",
    "# get the test set, selecting the index for grid given the interpolation assuption\n",
    "# notice that theta is the third parameter\n",
    "_, _, df_test = get_dataset_split(grid_X[:,:,theta_test_list_idx,:,:,:], \n",
    "                                  grid_y[:,:,theta_test_list_idx,:,:,:], \n",
    "                                  None, window_size=20, overlap_size=19,\n",
    "                                  label_treshold=1, split_on_run=True, shuffle_run=False, \n",
    "                                  shuffle_window=False, test_size = 0.3, val_size=0.2, \n",
    "                                  get_validation=True, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.iloc[:,:-1].to_numpy(), df_train.future_flare.to_numpy()\n",
    "X_val, y_val = df_val.iloc[:,:-1].to_numpy(), df_val.future_flare.to_numpy()\n",
    "X_test, y_test = df_test.iloc[:,:-1].to_numpy(), df_test.future_flare.to_numpy()\n",
    "X = np.vstack((X_train, X_val, X_test))\n",
    "y = np.hstack((y_train, y_val, y_test))\n",
    "print('X ## Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n",
    "print('y ## Train:', y_train.shape, 'Val:', y_val.shape, 'Test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = Constant([np.log(true/pos)])\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(20, activation='relu'), input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid',bias_initializer=initial_bias))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[f1_m, 'accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "# define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(\"models\", \"LSTM_extrpTheta_checkpoint.h5\"), save_weights_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "]\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "y_pred = np.round(model.predict(X_val), 0)\n",
    "\n",
    "print(\"### Evaluation on validation set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_val)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_val, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_val, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred = np.round(model.predict(X_test), 0)\n",
    "\n",
    "print(\"### Evaluation on test set ###\")\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_pred, y_test)))\n",
    "print(\"F1 Macro score: %.2f\" % (f1_score(y_pred, y_test, average='macro')))\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6GqkMZPr-ETk"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
